<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.3 20210610//EN" "JATS-journalpublishing1-3.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article" dtd-version="1.3" xml:lang="en">
  <front>
    <journal-meta>
      <journal-id journal-id-type="publisher-id">mathematics</journal-id>
      <journal-title-group>
        <journal-title>Mathematics</journal-title>
        <abbrev-journal-title abbrev-type="publisher">Mathematics</abbrev-journal-title>
        <abbrev-journal-title abbrev-type="pubmed">Mathematics</abbrev-journal-title>
      </journal-title-group>
      <issn pub-type="epub">2227-7390</issn>
      <publisher>
        <publisher-name>MDPI</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="doi">10.3390/math10050683</article-id>
      <article-id pub-id-type="publisher-id">mathematics-10-00683</article-id>
      <article-categories>
        <subj-group>
          <subject>Article</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Efficient Prediction of Court Judgments Using an LSTM+CNN Neural Network Model with an Optimal Feature Set</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0002-5533-3203</contrib-id>
          <name>
            <surname>Alghazzawi</surname>
            <given-names>Daniyal</given-names>
          </name>
          <xref rid="af1-mathematics-10-00683" ref-type="aff">1</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Bamasag</surname>
            <given-names>Omaimah</given-names>
          </name>
          <xref rid="af2-mathematics-10-00683" ref-type="aff">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3796-0294</contrib-id>
          <name>
            <surname>Albeshri</surname>
            <given-names>Aiiad</given-names>
          </name>
          <xref rid="af2-mathematics-10-00683" ref-type="aff">2</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Sana</surname>
            <given-names>Iqra</given-names>
          </name>
          <xref rid="af3-mathematics-10-00683" ref-type="aff">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Ullah</surname>
            <given-names>Hayat</given-names>
          </name>
          <xref rid="af3-mathematics-10-00683" ref-type="aff">3</xref>
        </contrib>
        <contrib contrib-type="author">
          <contrib-id contrib-id-type="orcid" authenticated="true">https://orcid.org/0000-0003-3320-2074</contrib-id>
          <name>
            <surname>Asghar</surname>
            <given-names>Muhammad Zubair</given-names>
          </name>
          <xref rid="af3-mathematics-10-00683" ref-type="aff">3</xref>
          <xref rid="c1-mathematics-10-00683" ref-type="corresp">*</xref>
        </contrib>
      </contrib-group>
      <contrib-group>
        <contrib contrib-type="editor">
          <name>
            <surname>Liou</surname>
            <given-names>James</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
        <contrib contrib-type="editor">
          <name>
            <surname>Kaklauskas</surname>
            <given-names>Art&#x16B;ras</given-names>
          </name>
          <role>Academic Editor</role>
        </contrib>
      </contrib-group>
      <aff id="af1-mathematics-10-00683"><label>1</label>Department of Information Systems, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 80200, Saudi Arabia; <email>dghazzawi@kau.edu.sa</email></aff>
      <aff id="af2-mathematics-10-00683"><label>2</label>Department of Computer Science, Faculty of Computing and Information Technology, King Abdulaziz University, Jeddah 80200, Saudi Arabia; <email>obamasek@kau.edu.sa</email> (O.B.); <email>aaalbeshri@kau.edu.sa</email> (A.A.)</aff>
      <aff id="af3-mathematics-10-00683"><label>3</label>Institute of Computing and Information Technology (ICIT), Gomal University, Dera Ismail Khan 29220, Pakistan; <email>iqrasana20@gmail.com</email> (I.S.); <email>hayyat.ullah2468@gmail.com</email> (H.U.)</aff>
      <author-notes>
        <corresp id="c1-mathematics-10-00683"><label>*</label>Correspondence: <email>zubair@gu.edu.pk</email>; Tel.: +92-335-0505657</corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>22</day>
        <month>02</month>
        <year>2022</year>
      </pub-date>
      <pub-date pub-type="collection">
        <month>03</month>
        <year>2022</year>
      </pub-date>
      <volume>10</volume>
      <issue>5</issue>
      <elocation-id>683</elocation-id>
      <history>
        <date date-type="received">
          <day>26</day>
          <month>12</month>
          <year>2021</year>
        </date>
        <date date-type="accepted">
          <day>17</day>
          <month>02</month>
          <year>2022</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>&#xA9; 2022 by the authors.</copyright-statement>
        <copyright-year>2022</copyright-year>
        <license license-type="open-access">
          <license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p>
        </license>
      </permissions>
      <abstract>
        <p>As the amount of historical data available in the legal arena has grown over time, industry specialists are driven to gather, compile, and analyze this data in order to forecast court case rulings. However, predicting and justifying court rulings while using judicial facts is no easy task. Currently, previous research on forecasting court outcomes using small experimental datasets yielded a number of unanticipated predictions utilizing machine learning (ML) models and conventional methodologies for categorical feature encoding. The current work proposes forecasting court judgments using a hybrid neural network model, namely a long short-term memory (LSTM) network with a CNN, in order to effectively forecast court rulings using historic judicial datasets. By prioritizing and choosing features that scored the highest in the provided legal data set, only the most pertinent features were picked. After that, the LSTM+CNN model was utilized to forecast lawsuit verdicts. In contrast to previous related experiments, this composite model&#x2019;s testing results were promising, showing 92.05 percent accuracy, 93 percent precision, 94 percent recall, and a 93 percent F1-score.</p>
      </abstract>
      <kwd-group>
        <kwd>court judgment prediction</kwd>
        <kwd>judicial data</kwd>
        <kwd>deep learning</kwd>
        <kwd>neural networks</kwd>
        <kwd>feature selection</kwd>
      </kwd-group>
      <kwd-group kwd-group-type="MSC">
        <title>MSC</title>
        <kwd>6204</kwd>
      </kwd-group>
    </article-meta>
  </front>
  <body>
    <sec id="sec1-mathematics-10-00683" sec-type="intro">
      <title>1. Introduction</title>
      <p>With the introduction of artificial intelligence, data mining applications have become increasingly frequently used in a variety of fields, including commerce, academia, medicine, and litigation. Computational approaches, such as those used in other disciplines, allow the law sector to gather and evaluate a large amount of legal data available in judiciary archives. Furthermore, examining such judiciary data to forecast legal outcomes not only reduces the strain on court employees but also allows for prompt decision-making, resulting in the effective processing of cases [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>].</p>
      <sec id="sec1dot1-mathematics-10-00683">
        <title>1.1. The Importance of Forecasting Court Case Judgements</title>
        <p>The basis of each lawsuit in the field of law is complicated since there are many linkages and interconnections between existing instances, and a jury&#x2019;s conclusions for comparable cases should be nearly the same. However, the intricacy of a case, as well as the presence of human participation, frequently results in different outcomes for cases that are otherwise comparable. As a result, computational and predictive algorithms can aid courts and attorneys in making the best decisions possible, thereby resolving such issues. Moreover, this may assist non-legal specialists in comprehending the fundamentals of a certain case or situation [<xref ref-type="bibr" rid="B2-mathematics-10-00683">2</xref>].</p>
        <p>Deep learning (DL) is a new branch of computer science that automatically extracts from previous data and efficiently predicts outcomes using a sophisticated set of feature embedding algorithms [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>]. It is used to forecast stock prices [<xref ref-type="bibr" rid="B4-mathematics-10-00683">4</xref>], personality recognition [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>], disease prediction [<xref ref-type="bibr" rid="B5-mathematics-10-00683">5</xref>], text categorization [<xref ref-type="bibr" rid="B6-mathematics-10-00683">6</xref>], and others [<xref ref-type="bibr" rid="B7-mathematics-10-00683">7</xref>]. Data scientists in the legal field are encouraged to develop practical solutions that will assist lawyers and judges in accurately forecasting judicial judgments [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>,<xref ref-type="bibr" rid="B2-mathematics-10-00683">2</xref>]. As a result, it is critical to research and apply cutting-edge DL techniques to historical records from the legal arena for the accurate assessment of judicial outcomes.</p>
      </sec>
      <sec id="sec1dot2-mathematics-10-00683">
        <title>1.2. Research Motivation</title>
        <p>Several works looked at leveraging historic judicial records to forecast judicial decisions exploiting computational methods such as machine learning [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>,<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>]. However, the central emphasis of these investigations, was entirely on the earlier detection of judicial case judgements. They were also constrained by (i) a limited choice of predictors utilized to represent court case judgments and (ii) conventional encoders that attempted to address the connection between the predictors in the judicial dataset. As a result, the LSTM+CNN model developed in this work took advantage of enhanced feature selection strategies. An RFE test was employed in the first phase to determine effective predictors for court case judgments. In the following stage, a long-term, short-term memory (LSTM) and a convolutional neural network (CNN) were employed to anticipate court judgments from a given legal set of data.</p>
      </sec>
      <sec id="sec1dot3-mathematics-10-00683">
        <title>1.3. Baseline Work</title>
        <p>We employed machine learning to model a system for forecasting judicial case judgments based on past judicial data [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]. It is intended to anticipate court outcomes using machine learning techniques such as support vector machines (SVM), k-nearest neighbors (KNN), and naive Bayes (NB). While choosing effective predictors ahead of applying machine learning to huge data sets may provide remarkable results, machine learning classifiers utilize a traditional encoding method that does not capture the overall connections between predictor variables in a machine learning-based data set [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>]. As a result, traditional machine learning classifiers may not provide an effective technique for forecasting judicial cases from judicial knowledge.</p>
        <p>To overcome the shortcomings of this baseline study [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>], we developed an efficient feature selection approach augmented with a deep learning model (LSTM+CNN), which was previously effectively used in a wide range of applications, including personality classification [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>], plant disease classification [<xref ref-type="bibr" rid="B6-mathematics-10-00683">6</xref>], concept-level sentiment analysis [<xref ref-type="bibr" rid="B9-mathematics-10-00683">9</xref>,<xref ref-type="bibr" rid="B10-mathematics-10-00683">10</xref>], and others [<xref ref-type="bibr" rid="B2-mathematics-10-00683">2</xref>]. We used an RFE test to pick features and, subsequently, an LSTM+CNN model to predict court cases.</p>
        <p>The process is as described in the following: (i) an RFE test was used to identify highly ranked features that contribute significantly to forecasting judicial case judgments; (ii) the LSTM model makes use of context by maintaining long-term interrelationships; and (iii) the convolutional neural network (CNN) system forecasted court case judgments effectively. As a result, the suggested technique offers the advantages of both optimum feature selection and LSTM and CNN layers for predicting court case judgments from past judicial records.</p>
      </sec>
      <sec id="sec1dot4-mathematics-10-00683">
        <title>1.4. Problem Statement</title>
        <p>Prior to actually going on to model design and development, it is required to first describe the prediction problem. Using past judicial data to forecast court case judgments is difficult owing to several reasons, including inadequate predictors choice, sparse judicial data sets, and the usage of conventional feature sets accompanied by ML algorithms [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>,<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>,<xref ref-type="bibr" rid="B9-mathematics-10-00683">9</xref>]. Additionally, resulting from poor predictors choices and a lack of hybrid models, DL models are less efficient when used in court case prediction. To address these challenges, we consider forecasting judicial case judgments from judicial data to be a multi-criteria prediction problem in which the court judgment is predicted from a given judicial data collection. The problem statement in this research is described as follows: A flow of legal training data &#x2018;CD = [cd1, cd2, cd3,...cdn]&#x2019; was fed into the system in order to forecast the ultimate court judgement, i.e., T1 (affirm), T2 (reverse), and T3 (other). Our objective was to develop a deep learning model that learnt from supplied training data in order to predict the final court judgement in the judicial domain using a deep neural network model with enhanced feature selection.</p>
      </sec>
      <sec id="sec1dot5-mathematics-10-00683">
        <title>1.5. Research Objectives</title>
        <p><xref ref-type="table" rid="mathematics-10-00683-t001">Table 1</xref> show the study objectives that were addressed in order to efficiently forecast court case judgments.</p>
      </sec>
      <sec id="sec1dot6-mathematics-10-00683">
        <title>1.6. Research Contributions</title>
        <p>This paper makes the following research contributions:<list list-type="order"><list-item><p>The use of recursive feature elimination (RFE) to rank and choose optimal features is critical for forecasting court judgments.</p></list-item><list-item><p>The use of a deep learning model (LSTM+CNN) to forecast court judgments.</p></list-item><list-item><p>Evaluating the effectiveness of traditional machine learning classifiers vs. the proposed deep learning model in predicting court judgments.</p></list-item><list-item><p>Prediction of court judgments in terms of three decision classes.</p></list-item><list-item><p>Evaluating the suggested approach&#x2019;s effectiveness against other deep learning and benchmark research.</p></list-item><list-item><p>The suggested approach increases the performance of the model for court case judgments by a substantial margin.</p></list-item></list></p>
        <p>The remainder of this study is arranged as follows: <xref ref-type="sec" rid="sec2-mathematics-10-00683">Section 2</xref> outlines the existing literature, whereas <xref ref-type="sec" rid="sec3-mathematics-10-00683">Section 3</xref> explains the suggested approach&#x2019;s methods. The findings and discussion are presented in <xref ref-type="sec" rid="sec4-mathematics-10-00683">Section 4</xref>, and the conclusion and future applications for the suggested technique are presented in the final section.</p>
      </sec>
    </sec>
    <sec id="sec2-mathematics-10-00683">
      <title>2. Review of Existing Literature</title>
      <p>This section provides an overview of prior legal research on lawsuit forecasting.</p>
      <p>Several machine learning (ML) classifiers were already used recently to forecast judicial case judgments based on past judicial records. Using a machine learning classifier and a large legal database, [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>] researched and used more effective collections of predictors. Experiments showned that including feature selection into predictive classifiers improves their performance substantially. [<xref ref-type="bibr" rid="B11-mathematics-10-00683">11</xref>] used a random forest (RF) classifier to analyze data from the United States Supreme Court. The selection of effective indicators prior to implementing machine learning on a big data set may have provided more promising outcomes, despite the fact that their system attained good accuracy in the cases and voting level judgments. Following the extraction of features, [<xref ref-type="bibr" rid="B12-mathematics-10-00683">12</xref>] suggested an SVM classifier for the prediction of court verdicts in criminal cases. Despite the fact that their method was more than 80% accurate, more research is needed because it only dealt with a small portion of the criminal proceeding data. A supervised machine learning approach, SVM, was developed by [<xref ref-type="bibr" rid="B13-mathematics-10-00683">13</xref>] to forecast decisions made by the French Supreme Court. The method was combined with a traditional feature extraction scheme, which was centered on an n-gram structure. In addition, n-fold cross-validation was performed to examine the outcome of the research. Their model, on the other hand, must be improved in order to evaluate the balanced data. Word embedding and other sophisticated feature engineering approaches are employed in deep learning (DL) models to improve the performance of ML techniques. [<xref ref-type="bibr" rid="B14-mathematics-10-00683">14</xref>] suggest a neural network that uses attention to recognize the charge and retrieve all potential articles in each situation. When constructing the suggested model, a variety of methods were employed, including support vector machine learning (SVM), a neural network model (Bi-GRU), and stochastic gradient descent with positional labelling (SGDLP). Cases involving many defendants could not be effectively handled with this approach, so it must be enhanced in this regard. Using the legal factual summary of the case, an official report and a judicial declaration may be generated automatically. On the other hand, [<xref ref-type="bibr" rid="B15-mathematics-10-00683">15</xref>] developed an LSTM-based encoder and decoder system. The collection consists of court records from China. However, the approach was restricted in breadth since it only prioritized situations with one charge and one defendant, excluding cases with several allegations and defendants. However, by incorporating more advanced approaches such as reinforcement learning, the system&#x2019;s efficiency might be increased. To identify the result of criminal trials based on official case factors, [<xref ref-type="bibr" rid="B16-mathematics-10-00683">16</xref>] used a deep learning model that used neural networks to predict the outcome. This was conducted by utilizing an attention mechanism and Bi-GRU with DL. The Thai Supreme Court provided the data set of 1000 criminal proceeding verdicts. There were good findings from the model, with a 66.67% accuracy. However, the study&#x2019;s shortcomings include the fact that it only looked at criminal instances, and the model&#x2019;s effectiveness can only be improved by incorporating more attention processes. Prediction models were also developed using hybrid DL models. [<xref ref-type="bibr" rid="B2-mathematics-10-00683">2</xref>] used DL and ML models to make predictions about violations of human rights. They used Bi-GRU to analyze data from the public database of human rights. In spite of the model&#x2019;s higher performance in terms of enhanced accuracy, f-measure, precision, and recall, hybridized deep learning models with optimum sets of attributes may still be built upon to even further enhance it. Numerous other methods were employed in addition to machine learning and deep learning models in order to forecast court judgments. On various data sets taken from Chinese court papers and encoded using the cascaded jump approach, [<xref ref-type="bibr" rid="B17-mathematics-10-00683">17</xref>] discovered that topology training is an innovative technique for predicting multitasking judgement learning and, therefore, for rendering judgement prediction. In spite of the fact that it had several shortcomings, including a lack of familiarity with numerous charges, the system could deliver effective outcomes if such shortcomings were properly resolved. [<xref ref-type="bibr" rid="B18-mathematics-10-00683">18</xref>] suggested a key phrase information gathering approach for court documentation. Semantic-driven searches were performed on the data collection of articles, including Indian Supreme Court rulings, using approaches such as POS tagging and NER. The inclusion of unnecessary connections in the graph-based approach affected efficiency, even if they were readily deleted. [<xref ref-type="bibr" rid="B19-mathematics-10-00683">19</xref>] employed Markov logic to recognize breakup decisions and case benchmark datasets from China&#x2019;s online judgement database. The approach enhanced outcomes for permitted and denied divorce petitions, but the research had a small sample size. Using alternative ML/DL methods could have enhanced the prediction.</p>
      <p>The European Court of Human Rights serves as an example of how natural language processing methods may be used to analyze court proceedings and forecast future judicial rulings [<xref ref-type="bibr" rid="B20-mathematics-10-00683">20</xref>]. The proposed technique predicts violations of nine articles of the European Convention on Human Rights with an overall accuracy of 75%, demonstrating the judicial domain&#x2019;s promise for machine learning techniques. On the other hand, the authors show, on the basis of previous examples, that making predictions about what decisions will be taken in the future based on previous examples degrades performance (the average accuracy ranges from 58 to 68%).</p>
      <p>Hsieh et al. [<xref ref-type="bibr" rid="B21-mathematics-10-00683">21</xref>] presented machine learning algorithms by providing the randomization feature with an important rating of legal considerations. The experiments show that &#x201C;the psychological distress losses claimed by the claimant&#x201D; and &#x201C;the age of the subject&#x201D; are important factors in determining how much emotional distress loss there were in fatal traffic collisions in Taiwan.</p>
      <p>Gaps in the Research: Although ML employs a traditional machine bag-of-words method as a feature representation technique, this drawback was already effectively solved using cutting-edge word embedding-based approaches in deep learning. However, the problem of managing contextual information through extensive feature extraction and convolutional neural networks should be addressed in order to achieve highly effective prediction of court case judgments employing hybrid deep learning approaches with selecting features and grading.</p>
    </sec>
    <sec id="sec3-mathematics-10-00683" sec-type="methods">
      <title>3. Proposed Methodology</title>
      <p>A multi-criteria decision-making solution using deep learning technology is needed to address such a complex prediction problem. Judiciary experts and lawyers may use data, knowledge, and predictions from our framework (see <xref ref-type="fig" rid="mathematics-10-00683-f001">Figure 1</xref>) to make judgments about court cases and reduce the burden on legal decision makers. The proposed system structure includes different subsystems, such as (i) data collection, (ii) preprocessing and feature selection, and (iii) predicting court judgments using the LSTM+CNN model.</p>
      <sec id="sec3dot1-mathematics-10-00683">
        <title>3.1. Judicial Dataset Collection</title>
        <p>We analyzed a sample of US Supreme Court rulings from the judicial repository [<xref ref-type="bibr" rid="B22-mathematics-10-00683">22</xref>]. This dataset was already frequently utilized by academics to build solutions for court case forecasting since it is not only codified by specialists but also includes detailed instructions on how to encode in the judiciary handbook. The judicial dataset we obtained had 120,506 cases. The judicial dataset contained 27 categorical predictor parameters (<xref ref-type="table" rid="mathematics-10-00683-t002">Table 2</xref>). Professionals expertly encoded these model parameters with different numeric representations, and the explanation of each categorized predictor and its binary values is accessible online at the Court&#x2019;s webpage [<xref ref-type="bibr" rid="B23-mathematics-10-00683">23</xref>]. A sample of court cases (without numeric encoding) is shown in <xref ref-type="table" rid="mathematics-10-00683-t002">Table 2</xref>. This manuscript includes a comprehensive data set as supplemental material.</p>
        <p>To perform the tests, we saved the dataset as a Microsoft Excel sheet, which was then converted into CSV format. The command line parameter &#x201C;pd.read csv&#x201D; was used to read the &#x201C;csv&#x201D; data source file, which is an important Pandas utility. Using the sklearn train test split function, the original data was divided into two parts: the train set and the testing sets [<xref ref-type="bibr" rid="B24-mathematics-10-00683">24</xref>]. It was then further divided into 80% training sets and 20% testing sets.</p>
        <p>Train set: The model was trained using the training set, with approximately 80% of the data used for the training phase [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]. The training set contained both the output labels (the dependent variable) and the input parameters (the predictor variable).</p>
        <p>Validation set: In the proposed methodology, the validation data were also employed to mitigate performance defects such as overfitting and underfitting. As a consequence, a 10-percent validation sample was used for model evaluation or parameterization [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>]. In Keras, settings could be adjusted in two ways: manually or automatically. We utilized the automatic verification technique in this research since it provides a fair evaluation of the proposed system.</p>
        <p>Test set: The testing data was used to evaluate the effectiveness of the algorithm against previously encountered or unidentified instances. The testing set computed the model&#x2019;s final estimate [<xref ref-type="bibr" rid="B25-mathematics-10-00683">25</xref>]. We employed 10% of the test dataset that was independent of the training dataset. Once the system was completely trained, the training data set was only used once. Lastly, the model was analyzed using test data. </p>
        <p>Treatment: To validate the model, we employed 10-fold cross-validation. At each training step, 10 training instances were collected. After training on each of the nine subsets of nine folds, the model was assessed on the last &#x201C;holdout&#x201D; sample. We selected the model with the greatest F1 score on the holdout sample. Using the final model developed at each training step, one may estimate how well the whole Supreme Court will rule on a certain case. This decision depends on the court&#x2019;s previous decisions, the tribunal&#x2019;s previous decisions, and all prior judgments. This practice is comparable to that utilized of a judicial authority when making detailed ex post facto judgments [<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>]. </p>
      </sec>
      <sec id="sec3dot2-mathematics-10-00683">
        <title>3.2. Preprocessing</title>
        <p>An efficient prediction model needs proper pretreatment of the gathered judicial set of data since a noisy data set causes poor performance of the suggested system. The data preprocessing module includes Handling imbalanced Dataset, optimum feature selection as well as value replacement for null values.</p>
        <sec id="sec3dot2dot1-mathematics-10-00683">
          <title>3.2.1. Handling Imbalanced Dataset</title>
          <p>The source dataset was substantially unbalanced [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>] and was treated unequally across all three categories: T1 = 11120, T2 = 9951, and T3 = 4556. Whenever a model learnt of distorted and uneven classified data, the outcome typically tended to benefit the major class, while the smaller classes were ignored in the prediction phase. This was regarded as a problem of imbalanced classes [<xref ref-type="bibr" rid="B24-mathematics-10-00683">24</xref>].</p>
          <p>To overcome this problem, we created a balanced dataset by employing a data processing sample technique, particularly oversampling, to rebalance all class instances. Oversampling is a technique used to increase the number of minor classes. The most basic technique of oversampling is randomized oversampling, which simply replicates small cases to raise the imbalance proportion [<xref ref-type="bibr" rid="B26-mathematics-10-00683">26</xref>]. In terms of efficient judicial case prediction, this replica of small class supplementation greatly improved the classifier performance. Algorithm 1 shows a random oversampling Pseudocode.
          <array><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin"><bold>Algorithm 1.</bold> Pseudocode of random oversampling.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin"><inline-formula><mml:math id="mm1"><mml:semantics><mml:mrow><mml:mn>1</mml:mn><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>b</mml:mi><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>m</mml:mi><mml:mi>p</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>S</mml:mi><mml:mi>i</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>i</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x2026;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>d</mml:mi><mml:mi>o</mml:mi></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula><break/><inline-formula><mml:math id="mm2"><mml:semantics><mml:mrow><mml:mn>2</mml:mn><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>c</mml:mi><mml:mi>u</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>e</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>e</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>k</mml:mi></mml:mstyle><mml:mo>&#x2212;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>y</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula><break/><inline-formula><mml:math id="mm3"><mml:semantics><mml:mrow><mml:mn>3</mml:mn><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>c</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>m</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>c</mml:mi><mml:mi>h</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>i</mml:mi><mml:mi>g</mml:mi><mml:mi>h</mml:mi><mml:mi>b</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>d</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi></mml:mstyle><mml:mo>.</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula><break/>4. Create synthesis instances at random anywhere along the lines connecting the minority instance and its m chosen peers (where m is a function of the intended level of oversampling).</td></tr></tbody></array></p>
          <p>Following the use of random oversampling, the balanced dataset was handled similarly across all three classes: T1:1040, T2:1040, and T3:1040. Total instances: 120,506.</p>
        </sec>
        <sec id="sec3dot2dot2-mathematics-10-00683">
          <title>3.2.2. Selection of the Most Effective Features</title>
          <p>The data set used to forecast court case judgments included a set of possible attributes that might help predict court case judgments. However, before using the prediction system to anticipate court case judgments, an appropriate collection of attributes (predictor variables) had to be chosen [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>].</p>
          <p>There were a number of potential features in the data set that could be used to forecast court judgments. However, before implementing the prediction system, an ideal collection of features (predictors) had to be determined in order to accurately predict lawsuit outcomes [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]. To select the most optimal attributes from a primary set of data, various approaches such as principal component analysis (PCA) [<xref ref-type="bibr" rid="B27-mathematics-10-00683">27</xref>], the chi-square (x2) test [<xref ref-type="bibr" rid="B12-mathematics-10-00683">12</xref>], and RFE [<xref ref-type="bibr" rid="B28-mathematics-10-00683">28</xref>] could be used.</p>
          <p>Yan and Zhang [<xref ref-type="bibr" rid="B29-mathematics-10-00683">29</xref>] used an RFE to prioritize and choose features from gas sensor data and achieved good results. RFE picks features by evaluating shorter and shorter groups of features iteratively. Firstly, the predictor is learned on the original feature set, and the significance of every feature is determined using any specified variable or iterator. The less significant features are therefore removed from the present list of features. This technique is continued iteratively on the trimmed subset until the appropriate set of attributes is obtained. It is calculated using Algorithm 2.
          <array><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin"><bold>Algorithm 2.</bold> Optimal feature selection using recursive feature elimination.</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin"><inline-formula><mml:math id="mm4"><mml:semantics><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mi>A</mml:mi></mml:mstyle><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mi>g</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>w</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>d</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>s</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;1. <inline-formula><mml:math id="mm5"><mml:semantics><mml:mrow><mml:mi>repeat</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;1.1 <inline-formula><mml:math id="mm6"><mml:semantics><mml:mrow><mml:mrow><mml:mi>compute</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>weight</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>wi</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>for</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>each</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>fi</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;1.2 <inline-formula><mml:math id="mm7"><mml:semantics><mml:mrow><mml:mrow><mml:mi>until</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>there</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>exists</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>fi</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>in</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>the</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>subset</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;2. <inline-formula><mml:math id="mm8"><mml:semantics><mml:mrow><mml:mrow><mml:mi>For</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>each</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>feature</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>fi</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>in</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>the</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>subset</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;2.1 <inline-formula><mml:math id="mm9"><mml:semantics><mml:mrow><mml:mrow><mml:mi>remove</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>feature</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>fi</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>with</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>smallest</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>wi</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;2.2 end<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;3. <inline-formula><mml:math id="mm10"><mml:semantics><mml:mrow><mml:mrow><mml:mi>For</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>each</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>feature</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>fi</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>in</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>the</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>subset</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="normal">S</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;3.1 <inline-formula><mml:math id="mm11"><mml:semantics><mml:mrow><mml:mrow><mml:mi>recompute</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="normal">w</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>on</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>reduced</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>feature</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>set</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="normal">F</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;3.2 end<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;4. <inline-formula><mml:math id="mm12"><mml:semantics><mml:mrow><mml:mrow><mml:mi>Identify</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>an</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>appropriate</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>number</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>of</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>features</mml:mi></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>predictors</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				B. Train and evaluate <inline-formula><mml:math id="mm13"><mml:semantics><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>p</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>f</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>o</mml:mi><mml:mi>p</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>t</mml:mi></mml:mstyle></mml:mrow></mml:semantics></mml:math></inline-formula> </td></tr></tbody></array></p>
          <p>On account of the strong correlation with target parameters, the top ten most important features are shown in <xref ref-type="table" rid="mathematics-10-00683-t003">Table 3</xref>. According to their rankings, the top-ranked features are grouped in order of significance to the target class.</p>
        </sec>
        <sec id="sec3dot2dot3-mathematics-10-00683">
          <title>3.2.3. Null Entries</title>
          <p>It is recommended that null entries or missing values be given for data cleaning to solve data discrepancies and optimize the predictive performance of the model [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]. There are three main methods for replacing a missing value: (i) directly compute the average and place this in the blank location; (ii) pick one item at random and replace it with the missing value; and (iii) replace the null value with the number of one step prior. We chose the third choice; therefore, the data was filtered by directly replacing the missing value with the proper higher value. Missing values were most typically caused by dividing by 0 when calculating predictors and decision variables on an individual basis [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]. Furthermore, before model training, we preprocessed the dataset and replaced any personal details (e.g., individual identities, ID numbers, addresses, and sexuality) with hyphens.</p>
        </sec>
      </sec>
      <sec id="sec3dot3-mathematics-10-00683">
        <title>3.3. A Brief Overview of the Proposed LSTM+CNN Model</title>
        <p>The prediction algorithms allows decision-makers to navigate through a number of possibilities and choose the best one. The key elements required to project court case judgments are prioritized as per their RFE relevance score. The suggested LSTM+CNN (long short-term memory + convolutional neural network) model (see <xref ref-type="fig" rid="mathematics-10-00683-f002">Figure 2</xref>) for predicting court verdicts operates as follows: (i) feature representation; (ii) the LSTM layer is integrated to maintain long-term interdependence; (iii) a dropout layer is used to reduce the possibility of overfitting; (iv) CNN is used to extract features; (v) a pooling layer is added to reduce the dimensionality of the convolved feature space; (vi) a flattening layer is added to flatten the pooled feature map into a feature set; and (vii) the softmax function is used in the output layer to forecast court case judgments.</p>
        <p>LSTM layer: In the beginning, an LSTM layer was deployed, which served as an encoder for the data. The input text comprised tokens, and each token was an output token that provided information regarding all previous tokens [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>].</p>
        <p>Dropout layer: In order to solve the problem of overfitting, the dropout layer employed a parameter called &#x201D;rate,&#x201D; which has a range of 0 to 1 values [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>].</p>
        <p>CNN layer: As part of the CNN architecture, the convolutional layer obtained improved information content from the LSTM layer and afterwards derived local patterns from that input via a convolutional operation. To construct the convolved feature space, the convolutional procedure employed a content matrix and a filtering matrix. Following that, a rectified linear unit activation function was employed to conduct nonlinear operations [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>].</p>
        <p>Pooling layer: The pooling layer made use of the maxpooling technique to compress the convolution feature map.</p>
        <p>Flatten layer: In the following stage, the flattening layer unrolled all of the entries from the pooled feature map into a feature space, allowing for further treatment.</p>
        <p>Prediction of judicial cases at output layer: Finally, inside the output layer, the softmax activation function was used to forecast court case judgments [<xref ref-type="bibr" rid="B30-mathematics-10-00683">30</xref>]. The softmax function calculated the probability values of the various court judgement classes, with the highest probability class being allocated to the particular lawsuit.</p>
      </sec>
      <sec id="sec3dot4-mathematics-10-00683">
        <title>3.4. Detailed View of Proposed Model</title>
        <p>The suggested deep learning approach, known as LSTM+CNN, was used to forecast legal case judgments such as T1 (affrim), T2 (reverse), and T3 (other). The suggested LSTM+CNN model has several layers, including an embedding layer, a long short-term memory layer, a dropout layer, a convolutional layer, a maxpooling layer, a flattening layer, and an output layer. The suggested LSTM+CNN model for predicting judicial case judgments from judicial material is depicted in detail in <xref ref-type="fig" rid="mathematics-10-00683-f003">Figure 3</xref>.</p>
        <sec id="sec3dot4dot1-mathematics-10-00683">
          <title>3.4.1. Embedding Layer</title>
          <p>The process of converting a discrete parameter (class) into a continuous array of numeric values is known as embedding (vectors). Bits in neural networks are low-dimensional matrix encodings of parameters used to train the model. It is desirable to use neural embeddings to minimize the number of features in categorical attributes and to significantly characterize classes in the resulting region. Keras streamlines the embedding implementation process. The obtained judicial data set had input data &#x2018;CD = [cd1, cd2, cd3,...], where the individual data item cd1 was converted into an embedding vector comprising continuous values, where d represents the data embedding dimensionality. The embedding layer was used to create a two-dimensional embedding matrix (feature matrix): <italic>M</italic>&#xCE; &#x211B;<sup>k&#x2019; l</sup>, where &#x2018;k&#x2019; signifies the input data&#x2019;s length and &#x2018;l&#x2019; denotes the dimension of a data embedding. After tokenizing the law data, it was fed to the embedding layer of the deep learning model for treatment, where it was transformed into a matrix of indexes. The embedding layer converted each index in the legal sequence into a vector containing streaming values. </p>
        </sec>
        <sec id="sec3dot4dot2-mathematics-10-00683">
          <title>3.4.2. LSTM Layer</title>
          <p>The second layer of our suggested approach is the LSTM layer. The embedding matrix is supplied in the long-term, short-term memory layer. This layer performs various computations with the use of four LSTM gates: the forget gate, input gate, candidate gate, and finally, the output gate. Long-term dependencies can be learned by the LSTM layer. <xref ref-type="fig" rid="mathematics-10-00683-f004">Figure 4</xref> depict a pictorial representation of the four gates computations. The computations begin with the forget gate <inline-formula><mml:math id="mm14"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, followed by the input gate <inline-formula><mml:math id="mm15"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, the candidate gate <inline-formula><mml:math id="mm16"><mml:semantics><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo mathvariant="bold-italic">~</mml:mo><mml:mi mathvariant="bold-italic">G</mml:mi></mml:mrow></mml:semantics></mml:math></inline-formula>, and the final output gate <inline-formula><mml:math id="mm17"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>. The embedding layer&#x2019;s data is transferred via a long-term memory cell, where computations begin with a forget gate in which the input <inline-formula><mml:math id="mm18"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> and the preceding output <inline-formula><mml:math id="mm19"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> are multiplied by their weights <inline-formula><mml:math id="mm20"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm21"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm22"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, and <inline-formula><mml:math id="mm23"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="mm24"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm25"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, <inline-formula><mml:math id="mm26"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="mm27"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>. Following that, addition is performed using bias vectors <inline-formula><mml:math id="mm28"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm29"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="mm30"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>. The sigmoid activation function is then used to modify the values between 0 and 1, and values larger than 0.5 are presumed to be 1 for three gates, as shown in the computation below. We used the tangent function for the candidate gate. The final output computation is transferred to the dropout layer.
          <disp-formula id="FD1-mathematics-10-00683"><label>(1)</label><mml:math id="mm31" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">=</mml:mo><mml:mi mathvariant="bold-italic">&#x3C3;</mml:mi><mml:mrow><mml:mo mathvariant="bold">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mo mathvariant="bold-italic">&#x2212;</mml:mo><mml:mn mathvariant="bold-italic">1</mml:mn></mml:mrow></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="bold">)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD2-mathematics-10-00683"><label>(2)</label><mml:math id="mm32" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">I</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">=</mml:mo><mml:mi mathvariant="bold-italic">&#x3C3;</mml:mi><mml:mrow><mml:mo mathvariant="bold">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo mathvariant="bold-italic">&#x2212;</mml:mo><mml:mn mathvariant="bold-italic">1</mml:mn></mml:mrow></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="bold">)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD3-mathematics-10-00683"><label>(3)</label><mml:math id="mm33" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">O</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">=</mml:mo><mml:mi mathvariant="bold-italic">&#x3C3;</mml:mi><mml:mrow><mml:mo mathvariant="bold">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo mathvariant="bold-italic">&#x2212;</mml:mo><mml:mn mathvariant="bold-italic">1</mml:mn></mml:mrow></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="bold">)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD4-mathematics-10-00683"><label>(4)</label><mml:math id="mm34" display="block"><mml:semantics><mml:mrow><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mo mathvariant="bold">~</mml:mo><mml:mi mathvariant="bold-italic">G</mml:mi><mml:mo mathvariant="bold">=</mml:mo><mml:mi mathvariant="bold-italic">&#x3C4;</mml:mi><mml:mrow><mml:mo mathvariant="bold">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Y</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo mathvariant="bold-italic">&#x2212;</mml:mo><mml:mn mathvariant="bold-italic">1</mml:mn></mml:mrow></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="bold">)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD5-mathematics-10-00683"><label>(5)</label><mml:math id="mm35" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">F</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">&#x2299;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mo mathvariant="bold-italic">&#x2212;</mml:mo><mml:mn mathvariant="bold-italic">1</mml:mn></mml:mrow></mml:msub><mml:mo mathvariant="bold">+</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">K</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">&#x2299;</mml:mo><mml:mi mathvariant="bold-italic">P</mml:mi><mml:msub><mml:mo mathvariant="bold">~</mml:mo><mml:mi mathvariant="bold-italic">G</mml:mi></mml:msub><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD6-mathematics-10-00683"><label>(6)</label><mml:math id="mm36" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">Q</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">O</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub><mml:mo mathvariant="bold">&#x2299;</mml:mo><mml:mi mathvariant="bold-italic">&#x3C4;</mml:mi><mml:mrow><mml:mo mathvariant="bold">(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">P</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow><mml:mo mathvariant="bold">)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>Cell state size is indicated by n, and input size is indicated by m. As you can see, <inline-formula><mml:math id="mm37"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">W</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> shows the vector size of the input gate weight matrices. The mapping weights of <inline-formula><mml:math id="mm38"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm39"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, <inline-formula><mml:math id="mm40"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="mm41"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">J</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> represent the matrices of the output gate. <inline-formula><mml:math id="mm42"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">a</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>,<inline-formula><mml:math id="mm43"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">b</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">c</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> and <inline-formula><mml:math id="mm44"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">d</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> are the bias vectors. <italic>&#x3C4;</italic> stands for the hyperbolic tangent function, and <italic>&#x3C3;</italic> stands for the sigmoid activation function. Below is a list of all the gates&#x2019; calculations.</p>
        </sec>
        <sec id="sec3dot4dot3-mathematics-10-00683">
          <title>3.4.3. Dropout Layer</title>
          <p>The primary goal of this layer is to avoid overfitting. The 0.5 value represents the &#x201C;rate&#x201D; parameter, which has a value between 0 and 1. The dropout layer casually deletes or randomly switches off neuron activity in the LSTM layer, depending on the application of dropout on the LSTM layer. Dropout modelling on a single neuron is shown in Equation (7).
          <disp-formula id="FD7-mathematics-10-00683"><label>(7)</label><mml:math id="mm45" display="block"><mml:semantics><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">F</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">r</mml:mi></mml:mstyle><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">s</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mi mathvariant="bold">r</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi mathvariant="bold">r</mml:mi><mml:mo mathvariant="bold">&#x2212;</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">s</mml:mi></mml:mstyle><mml:mo mathvariant="bold">=</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">s</mml:mi></mml:mstyle><mml:mo mathvariant="bold">=</mml:mo><mml:mn mathvariant="bold">1</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p><bold>r</bold> represents the intended outcomes, whereas s is the probability associated with real-valued word representation. As a result, if <bold>s</bold> = 1, the neuron with a real value is eliminated; otherwise, it is activated. <xref ref-type="fig" rid="mathematics-10-00683-f005">Figure 5</xref> depict the operation of a dropout layer. The embedding layer contains a real-valued depiction of certain data. As demonstrated in <xref ref-type="fig" rid="mathematics-10-00683-f005">Figure 5</xref>, when the dropout layer is applied, certain values inside an LSTM layer deactivate at random.</p>
        </sec>
        <sec id="sec3dot4dot4-mathematics-10-00683">
          <title>3.4.4. Convolutional Layer</title>
          <p>During the execution of this layer, a convolutional operation takes place, which is a mathematical operation executed over two functions, leading to the formation of a 3rd function. This procedure can be carried out by rearranging the dimensions of the (<italic>n</italic>) input matrix, the (<italic>t</italic>) filter matrix, and the (<italic>o</italic>) outcome matrix in the following ways:<disp-formula id="FD8-mathematics-10-00683"><label>(8)</label><mml:math id="mm46" display="block"><mml:semantics><mml:mrow><mml:mi>N</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mo>=</mml:mo><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>In Equation (8), <italic>N</italic> is the input matrix, which is formed by the LSTM layer, <inline-formula><mml:math id="mm47"><mml:semantics><mml:mo>&#x211D;</mml:mo></mml:semantics></mml:math></inline-formula> denotes all real values, <italic>u</italic> denotes the length, and <italic>v</italic> denotes the width of the input <inline-formula><mml:math id="mm48"><mml:semantics><mml:mrow><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mn>4</mml:mn><mml:mo>&#xD7;</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>.
		  <disp-formula id="FD9-mathematics-10-00683"><label>(9)</label><mml:math id="mm49" display="block"><mml:semantics><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>As shown in Equation (9), <italic>T</italic> stands for the filter matrices, <inline-formula><mml:math id="mm50"><mml:semantics><mml:mo>&#x211D;</mml:mo></mml:semantics></mml:math></inline-formula> stands for all real numbers, <italic>g</italic> stands for length, and <inline-formula><mml:math id="mm51"><mml:semantics><mml:mrow><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#xD7;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>.stands for the filter matrices&#x2019; breadth.
          <disp-formula id="FD10-mathematics-10-00683"><label>(10)</label><mml:math id="mm52" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi>O</mml:mi><mml:mo>&#xA0;</mml:mo></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></disp-formula>
          where in Equation (10), <italic>O</italic> is the output matrix, <inline-formula><mml:math id="mm53"><mml:semantics><mml:mo>&#x211D;</mml:mo></mml:semantics></mml:math></inline-formula> denotes all real numbers, <italic>w</italic> denotes length, and <italic>x</italic> denotes the output matrix&#x2019;s width, which is denoted by <inline-formula><mml:math id="mm54"><mml:semantics><mml:mrow><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#xD7;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>.</p>
          <p>Equation (11) show how to produce a convolutional operation.
          <disp-formula id="FD11-mathematics-10-00683"><label>(11)</label><mml:math id="mm55" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:munderover><mml:munderover><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi></mml:munderover><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow></mml:msub><mml:mo>&#x2297;</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>The elements of the output matrix <italic>O</italic><inline-formula><mml:math id="mm56"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi>&#x3F5;</mml:mi><mml:mo>&#xA0;</mml:mo><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>x</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> are represented by the letters <inline-formula><mml:math id="mm57"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">a</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, the elements of the filter matrix <italic>T</italic><inline-formula><mml:math id="mm58"><mml:semantics><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi>&#x3F5;</mml:mi><mml:mo>&#xA0;</mml:mo><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>d</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>, are represented by the letters <inline-formula><mml:math id="mm59"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula>, element-wise cross multiplication is represented by the letter (&#x2297;), and the element related to the input matrix <italic>N</italic> = <inline-formula><mml:math id="mm60"><mml:semantics><mml:mrow><mml:msup><mml:mo>&#x211D;</mml:mo><mml:mrow><mml:mi>u</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi>v</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> is represented by the <inline-formula><mml:math id="mm61"><mml:semantics><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">e</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">q</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula><sub>.</sub></p>
          <p>For example, the following convolutional operation is conducted on the dataset&#x2019;s initial data stream: (i) the components of the input matrix are 0.3, 0.6, 0, 0.5, (ii) The elements of the filter matrix are 0.8, 0.5, 0.4, 0.2, and (iii) the convolutional operation is 0.3 0.8 + 0.6 0.5 + 0 0.4 + 0.5 0.2 = 0.64, where 0.64 is the first element of the convolved feature map. Similarly, the element-wise cross multiplication and addition procedures continue until all of the values in the input matrix are covered, which will be accomplished by sliding a filter across the input matrix.</p>
          <sec>
            <title>Feature Map</title>
            <p>Once bias and activation functions are added to the convolved map, a feature map for a desired sentence is computed as described in Equation (12). </p>
            <p>After adding the bias and activation component to the convolved mapping, a feature map for specified data is produced as defined in Equation (12).
            <disp-formula id="FD12-mathematics-10-00683"><label>(12)</label><mml:math id="mm62" display="block"><mml:semantics><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">G</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">m</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">l</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></disp-formula></p>
            <p>A feature map has the dimensions = <inline-formula><mml:math id="mm63"><mml:semantics><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">S</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> = <inline-formula><mml:math id="mm64"><mml:semantics><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">S</mml:mi></mml:mstyle><mml:mrow><mml:mn>5</mml:mn><mml:mo>&#xD7;</mml:mo><mml:mn>4</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula> where b is the bias term and f is the activation function. In the rectified convolved feature map, the items are shown in the order they are presented:<disp-formula id="FD13-mathematics-10-00683"><mml:math id="mm65" display="block"><mml:semantics><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">G</mml:mi></mml:mstyle><mml:mo>&#xA0;</mml:mo><mml:mi mathvariant="bold">&#x3F5;</mml:mi><mml:mo>&#xA0;</mml:mo><mml:msup><mml:mi mathvariant="bold">S</mml:mi><mml:mrow><mml:mi mathvariant="bold">U</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi mathvariant="bold">V</mml:mi></mml:mrow></mml:msup><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
            <p>Following the convolutional process, the elements of every output matrix are simply added to the bias term.</p>
            <p>For example, adding a bias factor to the first member of the output matrix yields 0.64 + 1 = 1.64, which represents the first item of the feature map for a particular text (see <xref ref-type="fig" rid="mathematics-10-00683-f006">Figure 6</xref>).</p>
            <p>The parameters used in this layer, as shown in Algorithm No. 1, are: (i) &#x201C;filters,&#x201D; which displays the number of filters in the convolutional layer; (ii) &#x201C;kernel size,&#x201D; which displays the dimensions of the convolutional window; and (iii) &#x201C;padding,&#x201D; which retains a specific value among the three values, namely &#x201C;valid,&#x201D; &#x201C;same,&#x201D; and &#x201C;casual.&#x201D; If padding has the value &#x201C;valid,&#x201D; it means there is no padding. The term &#x201C;same&#x201D; padding indicates that the original data length is identical to the output length. Furthermore, if padding has the value &#x201C;casual,&#x201D; it will generate expanded convolution; (iv) the parameter &#x201C;activation = Relu&#x201D; demonstrates that activation is used to reveal nonlinear behavior.</p>
            <p>Ultimately, a feature map is created and the Relu activation function is employed to remove non-linearity. Its mathematical description is as follows: output = max (zero, input), where input is a feature map item. In the input data, for example, the first item in the feature space is 1.64. When the Relu activation process is conducted towards it, output = max (0, 1.64) changes to output = 1.64, since 1.64 &gt; 0. As a result, other corrected feature map pieces are computed for the particular data stream (see <xref ref-type="fig" rid="mathematics-10-00683-f007">Figure 7</xref>).</p>
          </sec>
        </sec>
        <sec id="sec3dot4dot5-mathematics-10-00683">
          <title>3.4.5. Pooling Layer</title>
          <p>The dimensionality of the feature map is reduced by obtaining information using the pooling layer. As a result, every sentence data input into a dataset is subjected to max pooling. By employing max pooling, the needed feature of a data stream is achieved by picking the largest value. Equation (13) show the formula for the pooling layer.
          <disp-formula id="FD14-mathematics-10-00683"><label>(13)</label><mml:math id="mm66" display="block"><mml:semantics><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">q</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">M</mml:mi><mml:mi mathvariant="bold">A</mml:mi><mml:mi mathvariant="bold">X</mml:mi></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">p</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">z</mml:mi><mml:mrow><mml:mi mathvariant="bold-italic">j</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">k</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold-italic">n</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
		  <inline-formula><mml:math id="mm67"><mml:semantics><mml:mrow><mml:msub><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">q</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">o</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="bold-italic">p</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> represents the items of the pooled feature map.</p>
          <p>The pooled feature map&#x2019;s length and width are indicated by P &#x3F5; <inline-formula><mml:math id="mm68"><mml:semantics><mml:mrow><mml:msup><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi mathvariant="bold">R</mml:mi></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mo>&#xD7;</mml:mo><mml:mi mathvariant="bold-italic">t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>. In this case, s stands for length, and t represents width. The &#x201C;MAX&#x201D; function is used to pick the top weight.</p>
          <p>A pooled feature map is generated in such a manner that the window size is set to (2 &#xD7; 2), the feature map is put on it, and lastly, the maximum element is retrieved from inside the window. In this instance, the highest item is 2.23, which also reflects the first item in the pooled feature map connected to the given data input among the window sizes chosen, i.e., max (1.64, 1.76, 1.80, and 2.23). As a result, a similar method will be followed for the supplemental values in the pooled feature map (see <xref ref-type="fig" rid="mathematics-10-00683-f008">Figure 8</xref>).</p>
        </sec>
        <sec id="sec3dot4dot6-mathematics-10-00683">
          <title>3.4.6. Flatten Layer</title>
          <p>This layer of the convolutional neural network converts the pooled feature map to a single vector, which is then fed into the neural network for prediction. For the required sentence, the feature map is represented as a single vector. To accomplish the flattening of the pooled feature map, as described in Equation (14), the reshaping operation of NumPy is used, which results in rows of feature vectors that are concatenated.
          <disp-formula>Flattening = pooled. reshape (4 &#xD7; 2, 1)<label>(14)</label></disp-formula></p>
          <p>The provided equation contains rows 1, 2, 3, and so on, and then attaches them all to create a single column vector. The flattened layer&#x2019;s objective is defined in <xref ref-type="fig" rid="mathematics-10-00683-f009">Figure 9</xref>, in which the matrix indicates the pooled feature map for specific data input and a single column vector representing the flattening operation that is conducted on a data stream pooled feature map.</p>
        </sec>
        <sec id="sec3dot4dot7-mathematics-10-00683">
          <title>3.4.7. Output Layer</title>
          <p>The CNN layer&#x2019;s final output is utilized as input to the output (final) layer, which uses the softmax algorithm to forecast court judgments. The following equation is utilized to generate the final output (see <xref ref-type="fig" rid="mathematics-10-00683-f010">Figure 10</xref>).
          <disp-formula id="FD15-mathematics-10-00683"><label>(15)</label><mml:math id="mm69" display="block"><mml:semantics><mml:mrow><mml:mrow><mml:msub><mml:mi mathvariant="normal">M</mml:mi><mml:mi mathvariant="normal">l</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mi>j</mml:mi><mml:mi>o</mml:mi></mml:msubsup><mml:msub><mml:mi>k</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:msub><mml:mi>n</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>q</mml:mi></mml:mrow></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>Equation (15) has <italic>n</italic> as the input, <italic>k</italic> as the weight, and <italic>q</italic> as the bias value.</p>
          <p>The &#x201C;softmax function&#x201D; is employed in order to compute the probability (see <xref ref-type="fig" rid="mathematics-10-00683-f011">Figure 11</xref>).
          <disp-formula id="FD17-mathematics-10-00683"><label>(16)</label><mml:math id="mm70" display="block"><mml:semantics><mml:mrow><mml:mi mathvariant="bold-italic">&#x3C3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:msup><mml:mi mathvariant="normal">&#x212E;</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">M</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mstyle displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mrow><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi mathvariant="bold-italic">h</mml:mi></mml:msubsup><mml:msup><mml:mi mathvariant="normal">&#x212E;</mml:mi><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">b</mml:mi><mml:mi mathvariant="bold-italic">k</mml:mi></mml:msub></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>The T1 court case judgement had the highest probability. In this trial, the forecasted court judgement is &#x201C;affirm&#x201D; (<xref ref-type="fig" rid="mathematics-10-00683-f011">Figure 11</xref>). The pseudo-code steps of the suggested system are depicted in Algorithm 3.
          <array><tbody><tr><td align="left" valign="middle" style="border-top:solid thin;border-bottom:solid thin"><bold>Algorithm 3:</bold> Pseudocode of proposed Court Case Judgments Prediction model.</td></tr><tr><td align="left" valign="top" style="border-bottom:solid thin"><list list-type="roman-upper"><list-item><label><bold>I.</bold>&#xA0;</label><p>Input: Court labelled dataset D as csv file.</p></list-item><list-item><label><bold>II.</bold>&#xA0;</label><p>Spilt into train (St<sub>rain,</sub> NR<sub>train</sub>)-test (S<sub>test,</sub> NS<sub>test</sub>) using Scikit learn.</p></list-item><list-item><label><bold>III.</bold>&#xA0;</label><p>Build the vocabulary to map integer to Legal data</p></list-item><list-item><label><bold>IV.</bold>&#xA0;</label><p>Transform each Court data stream into sequence of integers.</p></list-item><list-item><label><bold>V.</bold>&#xA0;</label><p>Procedure LSTM+CNN model(S<sub>train,</sub> NS<sub>train</sub>)</p></list-item></list>
				# Initialization of Sequential function<break/>
				Model=Sequential()<break/>
				# using Embedding Layer to map integers to low dimensional vectors<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Model.add (Embedding())<break/>
				#&#x2014;Applying LSTM layer for context information extraction<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Model.add (LSTM(100, return_sequence= true)))<break/>
				<inline-formula><mml:math id="mm71"><mml:semantics><mml:mrow><mml:mi>model</mml:mi><mml:mo>.</mml:mo><mml:mrow><mml:mi>add</mml:mi><mml:mo>&#xA0;</mml:mo></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>Conv</mml:mi><mml:mn>1</mml:mn><mml:mrow><mml:mi mathvariant="normal">D</mml:mi><mml:mo>&#xA0;</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>filters</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi>kernel</mml:mi></mml:mrow><mml:mo>_</mml:mo><mml:mi>size</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi>padding</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>&#x2018;</mml:mo><mml:mi>same</mml:mi><mml:mo>&#x2019;</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>&#xA0;</mml:mo><mml:mi>activation</mml:mi></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>&#x2018;</mml:mo><mml:mi>relu</mml:mi><mml:mo>&#x2019;</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula> <break/>
				Dropout Layer for preventing overfitting<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Model.add(Dropout(0.5))<break/>
				<inline-formula><mml:math id="mm72"><mml:semantics><mml:mrow><mml:mi>model</mml:mi><mml:mo>.</mml:mo><mml:mi>add</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>MAxPooling</mml:mi><mml:mn>1</mml:mn><mml:mi mathvariant="normal">D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mi>pool</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>size</mml:mi></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula><break/>
				<inline-formula><mml:math id="mm73"><mml:semantics><mml:mrow><mml:mi>model</mml:mi><mml:mo>.</mml:mo><mml:mi>add</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>Flattern</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> <break/>
				#Prediction of court case judgement using Softmax function<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;Model.add (Dense(3, activation=&#x2018;softmax&#x2019;)).<break/>
				# Compilation Function<break/>
				model. compile (loss = binary_crossentropy, optimizer = adamax, metrics= [accuracy])<break/>
				#Evaluate model on test data<break/>
				court_case_judgement= model. evaluate ()<break/>
				# Returning predicted court case judgement: &#x201C;T1&#x201D;, &#x201C;T2&#x201D;, &#x201C;T3&#x201D;<break/>
				Output: return judgement<break/>
				&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;&#xA0;End Procedure</td></tr></tbody></array></p>
        </sec>
        <sec id="sec3dot4dot8-mathematics-10-00683">
          <title>3.4.8. User Interface</title>
          <p>This section presents a software interface for forecasting court judgments written in Python and deployed with the Keras library [<xref ref-type="bibr" rid="B31-mathematics-10-00683">31</xref>]. Court judgement forecasting software is designed to help justices and lawyers make the correct decision. For simplicity and consistency, it was divided into modules based on the recommended approach. Three key modules make up the application&#x2019;s structure: (i) a module for collecting data and preprocessing it; (ii) learning a classifier and model; and (iii) court judgement forecasting. </p>
          <p>(i) Data gathering and preprocessing component: This module needs court case data input. After that, the data is preprocessed in the backend. The database is updated with much better data, and for each lawsuit, a unique case identifier is created. As a result of preprocessing, classifier implementation is carried out, and a model is developed that could be used to predict the result of court cases. The court case forecasting module makes predictions about the findings of a court&#x2019;s ruling depending on the actual data that has been entered. After entering the relevant data into the system, a distinctive lawsuit identifier is obtained, which is used to identify and track down each individual case. The interface shown in <xref ref-type="fig" rid="mathematics-10-00683-f012">Figure 12</xref> is used to input and preprocess data for a new input of the case. As previously stated, data is preprocessed at the backend of the application. The template that we developed is dynamic in nature, and the attributes of the form may be tailored to the requirements of each lawsuit. </p>
          <p>(ii) Training of the building model (LSTM+CNN): <xref ref-type="fig" rid="mathematics-10-00683-f013">Figure 13</xref> show a training set to display a dataset of judicial predictor variables that can be used to train classifiers and build models. This screen appears when a user selects the &#x201C;Model Train&#x201D; tab and the data loaded for training is presented. After clicking &#x201C;Model Train&#x201D;, a trained model is created.</p>
          <p>(iii) Predicting court judgment: Predicting the outcome of a court case is as simple as entering the relevant case information and clicking the &#x201C;Predict Court Judgment&#x201D; button. An updated training set is created when the &#x201C;update training set&#x201D; button is selected. When the user enters the case information and clicks on the &#x201C;predict court decision judgment&#x201D; tab, the outcomes are shown as &#x201C;T1: affirm&#x201D;, &#x201C;T2: reverse&#x201D;, and &#x201C;T3: other&#x201D;, along with a forecasted degree of confidence for each choice made. For a particular set of criteria, &#x201C;T1: Affirm&#x201D; is the expected outcome in a court case, as shown in <xref ref-type="fig" rid="mathematics-10-00683-f014">Figure 14</xref>.</p>
        </sec>
      </sec>
    </sec>
    <sec id="sec4-mathematics-10-00683" sec-type="results">
      <title>4. Results and Discussion</title>
      <p>This section describes the scientific results gained from a set of experiments undertaken in order to address the research questions provided in <xref ref-type="sec" rid="sec1-mathematics-10-00683">Section 1</xref>.</p>
      <sec id="sec4dot1-mathematics-10-00683">
        <title>4.1. Addressing Research Objectives</title>
        <sec id="sec4dot1dot1-mathematics-10-00683">
          <title>4.1.1. RO1: To Forecast Court Case Judgments Using LSTM+CNN on the Basis of Historical Judicial Data</title>
          <p>To accomplish the aforementioned research objective #1, we used different LSTM+CNN models to forecast court judgments using historical judicial data by modifying the parameters of the proposed LSTM+CNN model. The following settings were used: vocabulary vector size (53), embedding dimension (128), softmax activation function, dropout value (0.5, 0.8, 0.9), LSTM unit size (10, 15, 20, 30, 50, 60, 80, 100, 130, 150), number of epochs (7), number of filters (10, 16), filter size (8, 10), number of convolution layers (1), number of hidden layers (3), and batch size (8, 16, 32).</p>
          <p>The following equations (Equations (17) and (18)) were used to calculate precision and recall.</p>
          <p>As follows, <xref ref-type="table" rid="mathematics-10-00683-t004">Table 4</xref> show the results of each class&#x2019;s precision computations using Equation (17). For each category, we obtained <italic>P</italic>1, <italic>P</italic>2, and <italic>P</italic>3, the precision, <italic>Tc</italic>1, <italic>Tc</italic>2, and <italic>Tc</italic>3, and the true positives for each class, respectively.
          <disp-formula id="FD18-mathematics-10-00683"><label>(17)</label><mml:math id="mm74" display="block"><mml:semantics><mml:mrow><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>/</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD19-mathematics-10-00683"><mml:math id="mm75" display="block"><mml:semantics><mml:mrow><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD20-mathematics-10-00683"><mml:math id="mm76" display="block"><mml:semantics><mml:mrow><mml:mi>P</mml:mi><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD21-mathematics-10-00683"><mml:math id="mm77" display="block"><mml:semantics><mml:mrow><mml:mi>P</mml:mi><mml:mn>3</mml:mn><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p><xref ref-type="table" rid="mathematics-10-00683-t005">Table 5</xref> show the results of calculating the recall for each class using Equation (18). <italic>Tc</italic>1, <italic>Tc</italic>2, and <italic>Tc</italic>3 are the actual/true classes, and <italic>R</italic>1, <italic>R</italic>2, and <italic>R</italic>3 are the corresponding recalls; meanwhile, <italic>Tc</italic>1, <italic>Tc</italic>2, and <italic>Tc</italic>3 are the corresponding true positives.
          <disp-formula id="FD22-mathematics-10-00683"><label>(18)</label><mml:math id="mm78" display="block"><mml:semantics><mml:mrow><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>/</mml:mo><mml:mi>T</mml:mi><mml:mi>r</mml:mi><mml:mi>u</mml:mi><mml:mi>e</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD23-mathematics-10-00683"><mml:math id="mm79" display="block"><mml:semantics><mml:mrow><mml:mi>R</mml:mi><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD24-mathematics-10-00683"><mml:math id="mm80" display="block"><mml:semantics><mml:mrow><mml:mi>R</mml:mi><mml:mn>2</mml:mn><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD25-mathematics-10-00683"><mml:math id="mm81" display="block"><mml:semantics><mml:mrow><mml:mi>R</mml:mi><mml:mn>3</mml:mn><mml:mo>=</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>3</mml:mn><mml:mo>/</mml:mo><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>3</mml:mn><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>Specifically, Equations (19)&#x2013;(24) were used to compute the macro- and micro-averages of precision, recall, and F-measure, and the results are provided in <xref ref-type="table" rid="mathematics-10-00683-t006">Table 6</xref>.
          <disp-formula id="FD26-mathematics-10-00683"><label>(19)</label><mml:math id="mm82" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>p</mml:mi><mml:mn>3</mml:mn><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:mfrac><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD27-mathematics-10-00683"><label>(20)</label><mml:math id="mm83" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>p</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>P</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>P</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:mfrac><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD28-mathematics-10-00683"><label>(21)</label><mml:math id="mm84" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>c</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>T</mml:mi><mml:mi>n</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:mfrac><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD29-mathematics-10-00683"><label>(22)</label><mml:math id="mm85" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>R</mml:mi><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mn>2</mml:mn><mml:mo>+</mml:mo><mml:mi>R</mml:mi><mml:mn>3</mml:mn></mml:mrow><mml:mn>3</mml:mn></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD30-mathematics-10-00683"><label>(23)</label><mml:math id="mm86" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>F</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>/</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula>
          <disp-formula id="FD31-mathematics-10-00683"><label>(24)</label><mml:math id="mm87" display="block"><mml:semantics><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>F</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mn>2</mml:mn><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo>/</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>c</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mo>&#xA0;</mml:mo><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula></p>
          <p>According to the data shown in <xref ref-type="table" rid="mathematics-10-00683-t006">Table 6</xref>, the best performance was achieved using LSTM+CNN-model 10, which outperformed all other LSTM+CNN models.</p>
          <p><xref ref-type="table" rid="mathematics-10-00683-t007">Table 7</xref> show the accuracy, precision, recall, and f-score of the LSTM+CNN model (with and without feature selection).</p>
          <p><xref ref-type="table" rid="mathematics-10-00683-t008">Table 8</xref> display the training duration, test accuracy, and test loss for all 10 trials with varied parameter values in the LSTM+CNN model. The LSTM+CNN-10 model, with filter sizes (8), filters (16), and LSTM unit size (10), achieved the greatest accuracy (92.05%) of all the examined models.</p>
          <p><xref ref-type="table" rid="mathematics-10-00683-t009">Table 9</xref> show that when compared to not using feature selection, including features in the model significantly reduces the number of calculations required in terms of training and testing time while also improving accuracy. The experimental data and complexity analysis demonstrate that the proposed model may be used to anticipate court outcomes in actual environments with a high degree of accuracy in court forecasting scenarios.</p>
        </sec>
        <sec id="sec4dot1dot2-mathematics-10-00683">
          <title>4.1.2. Runtime Overhead of the Suggested LSTM+CNN with the Traditional SVM</title>
          <p>Computation costs are shown in <xref ref-type="table" rid="mathematics-10-00683-t010">Table 10</xref> as a sum over the entire number of multipliers applied to a single frame of data in convolution-based layers for the forward run. It is also possible to compute the total number of learnable model parameters. Using the LSTM+CNN, <xref ref-type="table" rid="mathematics-10-00683-t010">Table 10</xref> contrast the efficiency of the suggested approach with that of a standard SVM, and the results are encouraging. It also demonstrates that using LSTM+CNN improves accuracy by 0.7 percent while reducing computational costs when compared to regular SVM. Experiments and complexity analyses show that the model can be used to predict court cases with a fair amount of accuracy.</p>
        </sec>
        <sec id="sec4dot1dot3-mathematics-10-00683">
          <title>4.1.3. Complexity of the Proposed Algorithm</title>
          <p>Complexity of LSTM: Ultimately, we need to determine the time complexity of the LSTM+CNN algorithm. To accomplish this, we first need to compute the LSTM layer&#x2019;s and the convolutional layer&#x2019;s time complexity. Because LSTM is spatially and temporally local [<xref ref-type="bibr" rid="B23-mathematics-10-00683">23</xref>], the input length has no effect on the network&#x2019;s storage needs, and the time complexity per weight is O(1) for each time step. In other words, the total amount of time it takes to build an LSTM is O (w), where w is the number of weights.</p>
          <p>Complexity of CNN: According to [<xref ref-type="bibr" rid="B21-mathematics-10-00683">21</xref>], the complexity of all convolutional layers can be approximated by the equation <inline-formula><mml:math id="mm88"><mml:semantics><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:semantics></mml:math></inline-formula>, where k is the number of convolutional layers, <inline-formula><mml:math id="mm89"><mml:semantics><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:semantics></mml:math></inline-formula> is the number of filters in the jth layer, x is the number of input channels in the jth layer, Pj is the spatial size of the filter, and Yj is the spatial size of the output feature map; all of which are constants.</p>
          <p>Complexity of LSTM+CNN: The complexity of the LSTM+CNN per clock cycle may be estimated as the summation of the complexity of the LSTM layer and the complexity of the convolutional layers: <inline-formula><mml:math id="mm90"><mml:semantics><mml:mrow><mml:mi>O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>k</mml:mi></mml:munderover><mml:msub><mml:mi>x</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mi>p</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>.</mml:mo><mml:mo>&#xA0;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>.</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>j</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:semantics></mml:math></inline-formula> w). It is because of this that we can infer that our model has O complexity when it is written in the standard asymptotic nomenclature.</p>
        </sec>
        <sec id="sec4dot1dot4-mathematics-10-00683">
          <title>4.1.4. Effect of Parameters on Computation </title>
          <p>We conducted different experiments to measure the effects of parameters on the model&#x2019;s performance. Model hyperparameters include batch size &#x3B1;, number of convolution kernels (&#x3B2;), size of convolution kernel (&#x3B3;), and optimizer (&#x3B5;). There are some hyperparameters that can only be set manually and cannot be changed automatically during training. This has a big impact on the model&#x2019;s performance.</p>
          <p>Batch size(&#x3B1;): &#x3B1; is the number of training samples the neural network has, which tells us how many samples we will use to figure out how much we lost in each optimization step.</p>
          <p>Number of convolution kernels (&#x3B2;): &#x3B2; is the number of convolution kernels utilized in convolution, and how many feature maps will be created after convolution.</p>
          <p>Size of convolution kernels (&#x3B3;): The size of convolution kernels is represented by the symbol &#x3B3;. Convolution kernels have length, breadth, and depth. Convolution kernel length and breadth must be manually set in a CNN convolution layer. </p>
          <p>Optimizer &#x3B5;: When optimizing loss and then updating weight parameters, the kind of optimizer employed is known as Optimizer &#x3B5;.</p>
          <p>Therefore, we looked into how these &#x201C;super parameters&#x201D; might affect the performance of our hybrid LSTM+CNN model. We propose a hybrid LSTM+CNN model with the following parameters: a = 512, &#x3B2; = 4, &#x3B3; = 13, and &#x3B5; = Adam. The following are the model training outcomes for some of these specific parameters.</p>
          <p>Role of Batch_size &#x3B1;: <xref ref-type="fig" rid="mathematics-10-00683-f015">Figure 15</xref> show the results of our trials with &#x201C;&#x3B1;&#x201D; set to 128, 256, and 512. When a=128, the training loss converges quicker and reaches the set iterations in the same duration. Although a smaller batch size might speed up the optimization, this means that more computation time is required to optimize. The running speed and gradient decline direction can be improved by suitably increasing the batch size. The amplitude of training vibration is reduced in proportion to increased accuracy.</p>
          <p>Role of Number of convolution kernels (&#x3B2;): <xref ref-type="fig" rid="mathematics-10-00683-f016">Figure 16</xref> show the results of our experiments with different numbers of &#x201C;&#x3B2;&#x201D; (1, 2 and 4) convolution kernels. We obtained 0.9403 accuracy with one convolution kernel. The loss convergence rate grows as the number of convolution kernels doubles. With a value of four, the rate of loss convergence is considerably increased. In general, the deeper the network is, the more convolution kernels are needed to obtain all of the important characteristics.</p>
          <p>Role of Size of convolution kernels (&#x3B3;): In trials with convolution kernels of sizes 1 &#xD7; 2, 1 &#xD7; 3, and 1 &#xD7; 4, as indicated in the graph (<xref ref-type="fig" rid="mathematics-10-00683-f017">Figure 17</xref>), it is noticeable that when the convolution kernel is 1 &#xD7; 2 in size, the validation loss will fluctuate drastically. For a 1 &#xD7; 3 or 1 &#xD7; 4 convolution kernel, loss converge is faster, and the fluctuation range is less hence it is better to use a larger convolution kernel.</p>
        </sec>
        <sec id="sec4dot1dot5-mathematics-10-00683">
          <title>4.1.5. RO2: To Compare the Efficiency of the Suggested LSTM+CNN Approach to That of Machine Learning and Deep Learning Techniques</title>
          <p>To address the second research objective, &#x201C;To compare the efficiency of the suggested LSTM+CNN approach to that of machine learning and deep learning techniques&#x201D;, the results of the LSTM-CNN model for forecasting court judgments were contrasted with those of various traditional machine learning approaches as well as deep learning methods.</p>
          <p>Suggested model (LSTM+CNN) versus machine learning: The suggested approach (LSTM+CNN) was tested against standard machine learning models in order to evaluate its efficacy in forecasting court judgments using past judicial data. The standard machine learning algorithms make use of well-established feature representation approaches, such as the TF-IDF and the CountVectorizer. TF-IDF turns data into a feature vector that may be used for classification tasks, whereas the CountVectorizer uses the word counting approach. The embedding-based feature representation strategy was used to refer to the suggested LSTM+CNN. When enormous vocabulary sizes are considered, the embedding-based technique outperforms typical feature representation sets. <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref> summarize the outcomes of the machine learning models and the suggested model.</p>
          <list list-type="bullet">
            <list-item>
              <p>Proposed LSTM-CNN vs. KNN</p>
            </list-item>
          </list>
          <p>In this experiment, we compare the machine learning technique, namely K-nearest neighbors, with the proposed LSTM-CNN model. The assessment results of the machine learning model are shown in <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref>. In the investigation, the recommended LSTM-CNN outcomes are compared to the machine learning model K-nearest neighbors. The performance evaluation results for the machine learning algorithms are shown in <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref> (accuracy = 74 percent, pre = 0.75, recall = 0.75, and f-score = 0.75). KNN currently performs poorly. When working with huge data sets, (i) it is time-consuming and (ii) it is vulnerable to irrelevant and inconsistent data, which makes it an unfavorable option [<xref ref-type="bibr" rid="B32-mathematics-10-00683">32</xref>].</p>
          <list list-type="bullet">
            <list-item>
              <p>Proposed LSTM-CNN vs. SVM</p>
            </list-item>
          </list>
          <p>The purpose of this experiment was to compare the effectiveness of the proposed LSTM+CNN model to the performance of the classification classifier. As shown in <xref ref-type="table" rid="mathematics-10-00683-t007">Table 7</xref>, SVM classifiers performed worse in terms of precision (0.79), recall (0.78), F1-score (0.79), and accuracy (78%), as shown in <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref>. The poor behavior of the SVM model could be attributed to a variety of factors, including: (i) long training times; (ii) expensive computing; (iii) larger training and testing size requirements; and (iv) increased complexity [<xref ref-type="bibr" rid="B25-mathematics-10-00683">25</xref>].</p>
          <list list-type="bullet">
            <list-item>
              <p>Proposed LSTM-CNN vs. LR</p>
            </list-item>
          </list>
          <p>When an LSTM+CNN model was compared to a logistic regression (LR) classifier, the results were found to be more effective with the suggested model. <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref> demonstrate that LR classifiers provided lower precision (0.79), recall (0.79), F1-score (0.79), and accuracy (0.80). LR has a poor ranking because it (i) readily creates overfitting [<xref ref-type="bibr" rid="B25-mathematics-10-00683">25</xref>] and (ii) delivers relatively brief forecasts [<xref ref-type="bibr" rid="B33-mathematics-10-00683">33</xref>].</p>
          <list list-type="bullet">
            <list-item>
              <p>Proposed LSTM-CNN vs. RF</p>
            </list-item>
          </list>
          <p>The purpose of this experiment was to evaluate the effectiveness of the suggested LSTM+CNN model against that of a random forest (RF) classifier. The RF classifier provided lower precision (0.68 percent), recall (0.68 percent), F1-score (0.68 percent), and accuracy (0.69 percent), as shown in <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref>. The RF model performs poorly because: (i) real-time forecasting takes time; (ii) it is inconsistent for categorical groups of samples; and (iii) comparable sets of related attributes in the records are favored over bigger collections [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>].</p>
          <p>Suggested model (LSTM+CNN) versus deep learning: To assess the LSTM+CNN model&#x2019;s effectiveness in forecasting court judgments from past judicial material, it was contrasted to other deep learning (DL) methods including CNN, recurrent neural network (RNN), long/short-term memory (LSTM). <xref ref-type="table" rid="mathematics-10-00683-t012">Table 12</xref> summarize the findings.</p>
          <list list-type="bullet">
            <list-item>
              <p>CNN vs. Proposed LSTM-CNN</p>
            </list-item>
          </list>
          <p>The purpose of this experiment was to investigate the efficacy of the suggested LSTM+CNN model compared to that of a mono CNN model. According to <xref ref-type="table" rid="mathematics-10-00683-t012">Table 12</xref>, the CNN model had the worst outcomes in terms of precision, recall, F1-score, and accuracy. CNN is ranked low since it (i) does not save text sequence contextual information and (ii) needs a massive set of data to deliver enhanced classifier performance.</p>
          <list list-type="bullet">
            <list-item>
              <p>RNN vs. Proposed LSTM-CNN</p>
            </list-item>
          </list>
          <p>The objective of this investigation was to evaluate the efficiency of the suggested CNN+BiLSTM model compared to that of an RNN model. <xref ref-type="table" rid="mathematics-10-00683-t012">Table 12</xref> demonstrate that the RNN model performed poorly in terms of precision, recall, F1-score, and accuracy. Recurrent neural network models do not store information for lengthy periods of time because they are incapable of managing exceedingly long patterns. As a result, the RNN model produced unsatisfactory performance [<xref ref-type="bibr" rid="B3-mathematics-10-00683">3</xref>].</p>
          <list list-type="bullet">
            <list-item>
              <p>LSTM vs. Proposed LSTM-CNN</p>
            </list-item>
          </list>
          <p>The objective of this investigation was to evaluate the efficiency of the suggested CNN+BiLSTM model compared to that of a standard LSTM model. <xref ref-type="table" rid="mathematics-10-00683-t012">Table 12</xref> demonstrate that the LSTM model produced the worst outcomes in terms of accuracy, recall, F1-score, and precision. LSTM models only retain past context information and do not retain future context information, which would allow for more accurate comprehension of the context of the reviewed text. As a result, it performed the worst out of all models.</p>
        </sec>
        <sec id="sec4dot1dot6-mathematics-10-00683">
          <title>4.1.6. Ablation Study</title>
          <p>An ablation investigation into LSTM+CNN was carried out to examine the efficacy of each module. The ablation research specifics are as follows. The suggested LSTM+CNN model was altered in terms of the following four cases: without FS(model-1), without balancing (model-2), without LSTM (model-2), and without CNN(model-3). LSTM+CNN ablation research findings are given in <xref ref-type="table" rid="mathematics-10-00683-t013">Table 13</xref>, which includes additional analysis of LSTM+CNN&#x2019;s performance.</p>
          <p>When comparing LSTM+CNN to model 1, the accuracy of the model decreased when the FS module was removed because the method could not use the best attributes for classification. When comparing LSTM+CNN to model 2, the accuracy of model-2 decreased when the data balancing module was removed since the approach could not effectively classify skewed data. Compared with model 3, the efficacy of LSTM+CNN also indicated the effectiveness of LSTM+CNN. When we took the LSTM subsystem out of the system, the model&#x2019;s performance decreased because it could not obtain contextual data.</p>
          <p>It was also found that when the CNN component was excluded, the model could not find the local features of the stream, and CNN had a huge effect on how much the model was doing. </p>
        </sec>
        <sec id="sec4dot1dot7-mathematics-10-00683">
          <title>4.1.7. RO3: To Compare the Proposed Technique&#x2019;s Effectiveness in Forecasting Court Case Judgments from Past Judicial Records to Benchmark Research</title>
          <p>To answer the third research objective, &#x201C;to compare the proposed technique&#x2019;s effectiveness in forecasting court case judgments from past judicial records to benchmark research&#x201D;, we ran experiments to compare the efficiency of the proposed LSTM-CNN with the outcomes of other similar studies. To measure performance, the suggested system was compared to the benchmark approaches. <xref ref-type="table" rid="mathematics-10-00683-t014">Table 14</xref> provide the results of an experiment in which we evaluated the efficiency of the suggested LSTM+CNN model against that of baseline studies. However, a comprehensive evaluation of published approaches is problematic for a number of reasons. To start with, these models were evaluated on a wide range of datasets, which made it very difficult to compare them. Furthermore, the participating writer&#x2019;s publications provide the approaches in an abstract manner with little detail, making them worthless for future scholars.</p>
          <p>Ullah et al. [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]: used several machine learning approaches on judicial data sets. It was discovered that combining enhanced feature selection strategies with a DL model may increase the model&#x2019;s effectiveness.</p>
          <p>Zhu et al. [<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>]: After determining the facts, [<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>] presented a transformer-hierarchical-multi-extra (THME) network that would allow them to make full use of the information available. The conducted experiments used a massively large dataset of criminal proceedings in the civil courts, which is derived from the civil law system. According to the outcomes of the experiments, accuracy (78%) determined the model&#x2019;s low performance.</p>
          <p>Medvedeva et al. [<xref ref-type="bibr" rid="B20-mathematics-10-00683">20</xref>]: With a 75% overall accuracy rate, the suggested method can predict violations of nine articles of the European Convention on Human Rights. This shows that machine learning can be used in the courtroom.</p>
          <p>Hsieh et al. [<xref ref-type="bibr" rid="B21-mathematics-10-00683">21</xref>]: They offered a machine learning approach with a legitimate score for randomness. &#x201C;The psychological distress losses claimed by the claimant&#x201D; and &#x201C;the subject&#x2019;s age&#x201D; are key aspects in assessing emotional suffering and loss in traffic fatalities.</p>
          <p>Proposed work (our model): The suggested DL-based strategy for forecasting court case judgments was built on a better feature selection algorithm, which was then backed by a deep neural network. The experimental findings demonstrate that the proposed method surpasses benchmark research (<xref ref-type="table" rid="mathematics-10-00683-t014">Table 14</xref>) and that the chosen predictor parameters (10) considerably impact the forecasted (objective) parameter. The key reason for our good results is that we combined effective feature selection with the LSTM-CNN deep learning technique to forecast court case judgements. While the CNN layer can extract n-gram features, the LSTM layer may keep contextual information.</p>
        </sec>
      </sec>
      <sec id="sec4dot2-mathematics-10-00683">
        <title>4.2. Significance Test</title>
        <p>The LSTM-CNN (DL) and SVM (ML) models were evaluated in two tests to see if the DL model was statistically significant when compared to the SVM (ML) model. LSTM+CNN (DL) and SVM(ML) classifiers were used to classify the individual data inputs after 113 random data inputs were randomly selected from the corpus. Two hypotheses were be tested in the experiment:</p>
        <p>H<sub>null</sub>: The error rates in both models are identical.</p>
        <p>H<sub>alternate</sub>: The error rates in both models are significantly different.</p>
        <p>Equation (25) demonstrates McNemar&#x2019;s chi-squared statistical test:<disp-formula id="FD32-mathematics-10-00683"><label>(25)</label><mml:math id="mm91" display="block"><mml:semantics><mml:mrow><mml:msup><mml:mi mathvariant="sans-serif">&#x3C7;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>=</mml:mo><mml:mfrac bevelled="true"><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>&#x2212;</mml:mo><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mo>&#x2212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="normal">k</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="normal">l</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:semantics></mml:math></disp-formula></p>
        <p>To compute discordant test statistics, we used k and l, where 1 represents the degree of freedom and 2 represents chi-squared (<inline-formula><mml:math id="mm92"><mml:semantics><mml:mrow><mml:msup><mml:mi mathvariant="sans-serif">&#x3C7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:semantics></mml:math></inline-formula>).</p>
        <sec>
          <title>Analysis</title>
          <p>The utility of the LSTM-CNN model is demonstrated in <xref ref-type="table" rid="mathematics-10-00683-t015">Table 15</xref>, which demonstrates that the proposed method considerably enhanced results in predicting court case judgments with an accuracy of 92.05%. The LR algorithm underperformed for each of the prediction performance measures: accuracy, recall, F1-measure, and precision (as shown in <xref ref-type="table" rid="mathematics-10-00683-t011">Table 11</xref>). The significance test found that the difference between the deep learning model (LSTM-CNN) and the ML (LR) model is statistically significant. <xref ref-type="table" rid="mathematics-10-00683-t015">Table 15</xref> show that the two models differ in 10 of the input data assessments. A consistency adjustment was used to determine the p-value of McNemar&#x2019;s statistical test. There was a chi-squared score of 4.6, a p-value of 0.031, and a degree of independence of 1. A p-value under 0.5 confirmed the alternative hypothesis, rendering the null hypothesis false. As a consequence, the suggested model with embeddings outperformed the SVM model based on standard features by a statistically significant margin. This demonstrates how embedding-based features improve the LSTM+CNN model&#x2019;s predictive ability when used with past judicial datasets. </p>
        </sec>
      </sec>
      <sec id="sec4dot3-mathematics-10-00683">
        <title>4.3. External Validation of the Suggested Technique</title>
        <p>After internal validation of the suggested approach in <xref ref-type="sec" rid="sec4dot1dot1-mathematics-10-00683">Section 4.1.1</xref> to establish model stability, we gathered three more datasets, one for each of the years 2012, 2013, and 2014, to externally validate the developed model, as previously mentioned in <xref ref-type="sec" rid="sec3dot1-mathematics-10-00683">Section 3.1</xref>.</p>
        <p>By evaluating it on the datasets provided in this section, we were able to demonstrate that our approach for forecasting court case judgments is accurate and effective. To evaluate the suggested methodology, predictive models were implemented on the provided datasets both with and without suggested feature selection and data balancing strategies.</p>
        <p>Models trained on the main dataset (2017), in particular, were tested separately on the 2012&#x2013;2014 datasets. <xref ref-type="table" rid="mathematics-10-00683-t016">Table 16</xref> summarize the obtained findings. Models developed without dataset balance and feature selection had poor sensitivity scores (12&#x2013;20%) but very strong specificity scores (92&#x2013;95%). All these low sensitivity results show how important it is to solve the training issues caused by unbalanced data. In the next round, the outcomes did not decrease because they had already selected the features (but not balancing). When contrasted to a large set of variables, a lower number produced comparably accurate predictions (10 variables instead of 27). The dataset was then balanced (prior to selecting features) in the subsequent step (third row), leading to a substantially better proper balance between sensitivity (75 percent on average for 2012, 2013, and 2014) and specificity values (77 percent on average for 2012, 2013, and 2014). We employed both the feature selection technique and data balancing (the proposed model) in the final step, which increased the precision and recall levels by up to 82% on average between 2012 and 2014. The results of this series of investigations independently support the proposed approach as well as the possibility of improving its prediction effectiveness.</p>
      </sec>
    </sec>
    <sec id="sec5-mathematics-10-00683">
      <title>5. Challenges and Difficulties in Applying Judicial Prediction Methods in Real-Life Environments</title>
      <sec id="sec5dot1-mathematics-10-00683">
        <title>5.1. Preparation of Data</title>
        <p>Legal documents are an ideal source of data for deep learning, but there are several underlying barriers that need to be fixed before the data can be used. For example, tagging data channels (&#x2018;labels&#x2019;) with appropriate semantic knowledge to assist with such fundamental activities as introjected regulation by legislation through the law, regulations, and regulatory and judicial processes based on constitutional principles. Concerns regarding data privacy, confidentiality, and civil rights will also arise and require a lot of self-regulation by the people who develop these platforms [<xref ref-type="bibr" rid="B34-mathematics-10-00683">34</xref>].</p>
      </sec>
      <sec id="sec5dot2-mathematics-10-00683">
        <title>5.2. Data Labeling</title>
        <p>Employing data for machine learning generally necessitates some sort of ground truth link. Observational data must be easy to understand in order to make good judgments or inferences. Annotated data sets are often required to train prediction models. A barrier arises because data annotation is only accomplished by a limited group of specialists, specifically those familiar with the underlying technologies. This is the true bottleneck, owing to the complexities of the operations and data involved [<xref ref-type="bibr" rid="B35-mathematics-10-00683">35</xref>].</p>
      </sec>
      <sec id="sec5dot3-mathematics-10-00683">
        <title>5.3. The Scale of the Application</title>
        <p>It is difficult to achieve economies of scale since industrial processes are, by their very nature, highly technical. A solution designed for one court, for example, cannot be used in another. Civil and criminal court procedures will necessitate a separate set of rules and procedures. Because of this, there may be fewer studies relevant to machine learning in particular fields than there are in others [<xref ref-type="bibr" rid="B11-mathematics-10-00683">11</xref>].</p>
      </sec>
      <sec id="sec5dot4-mathematics-10-00683">
        <title>5.4. Potential Solutions</title>
        <p>There is no shortcut to developing industrial machine learning applications. Predictive analytics initiatives in the judicial sector have a high failure rate, which is evident in the fact that most of the projects that attempted execution before even collecting the data failed. A lot of work needs to be carried out before this goal can be reached. Data preparation and labeling, model construction, and improvement are all steps used to achieve this. In the complicated judicial process, technology can only serve as a supplementary tool for achieving timely decisions in court [<xref ref-type="bibr" rid="B35-mathematics-10-00683">35</xref>].</p>
      </sec>
    </sec>
    <sec id="sec6-mathematics-10-00683">
      <title>6. Statement of Ethical Principles and Practices</title>
      <p>Lastly, we want to draw attention to the ethical concerns of our research. Every machine learning model trained on large, unstructured data sets has the potential to perpetuate and amplify established social biases [<xref ref-type="bibr" rid="B36-mathematics-10-00683">36</xref>]. The obligation to maintain equality, judicial impartiality, and constitutional diversity should always be effectively addressed in judicial decisions, and be of great concern. To tackle these issues, we deleted personally identifying information from the data (e.g., sexual identity, ethnicity, and so forth). However, irrespective of any prejudice, the following would remain probable systems errors: (a) recognizing an incorrect legal fact; and (b) arriving at an incorrect judicial decision. As a result of these concerns, we were able to alleviate the uncertainty in our research by balancing the skewed data. We employed oversampling to adjust for uncommon items generated in order to sustain balanced training examples. Furthermore, we proposed an upcoming fully automated judgement forecasting algorithm function in an inclusive and diverse manner, allowing an individual to make changes at critical points (e.g., judicial fact identification) prior to the final stage (e.g., judgement forecasting), ensuring that the final judgement is valid. Similarly, anytime we attempted to manually adjust the solution during the factual test sheets, we noticed a significant increase in the accuracy of the forecasting of judgement.</p>
    </sec>
    <sec id="sec7-mathematics-10-00683" sec-type="conclusions">
      <title>7. Conclusions and Future Work</title>
      <p>Because of the significant increase in judiciary content, it is becoming more important to gather and analyze such data in order to forecast court decisions in judicial matters. In order to do this, an efficient DL model was designed and developed. The suggested model consists of three tasks: (i) obtaining benchmarks for judiciary data collection, (ii) feature selection, and (iii) predicting court case judgments using a deep neural network (LSTM+CNN). Several more tests were also carried out using the data set. In the supplied data collection, feature selection was used to choose just the key features by prioritizing and choosing the top-rated features. Finally, an LSTM+LSTM model was used to forecast court case judgments. When compared to other existing efforts, our experimental outcomes are promising. However, the following are significant shortcomings of the suggested model: (i) a small data set from a specific domain was used (standard judicial data set), (ii) only one statistical technique, the RFE measure, was applied to the input set of data to select the important features (predictor variables) [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>], (iii) embedding was used rather than a pre-trained CNN model, (iv) there were no efficient noise reduction techniques, and (v) it would be better if the model worked the same way over time, in different cases, and even with different judges. The efficacy of current models also varied greatly across time and between justices. It proved challenging for both legal experts and practicing lawyers to make effective use of prediction models. Rather than the conventional stationary system learning challenges, we encountered a more complicated situation. There are a lot of factors that could affect the overall result of a lawsuit, such as public perception, inter-branch disagreement, changes in justices and changes in their views, and prosecutorial standards and practices.</p>
      <p>Future research may investigate the use of judicial data sets from different domains (judicial data from various courts), the use of additional feature selection methods apart from the RFE, the use of pre-trained models such as word2Vec, Glove, or fastText, and investigate state-of-the-art noise reduction techniques.</p>
    </sec>
  </body>
  <back>
    <notes>
      <title>Author Contributions</title>
      <p>Conceptualization, D.A. and O.B.; methodology, D.A., O.B. and I.S.; software, H.U. and M.Z.A.; validation, M.Z.A. and H.U.; formal analysis, D.A. and A.A.; investigation, O.B.; resources, D.A., O.B. and A.A. data curation, O.B., I.S. and H.U; writing&#x2014;M.Z.A. and D.A.; original draft preparation, M.Z.A. and D.A.; writing&#x2014;D.A. and H.U.; visualization, O.B., M.Z.A. and A.A.; supervision, D.A.; project administration, D.A.; funding acquisition, D.A. All authors have read and agreed to the published version of the manuscript.</p>
    </notes>
    <notes>
      <title>Funding</title>
      <p>The authors extend their appreciation to the Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia, for funding this research work through the project number IFPRC-106-611-2020 and King Abdulaziz University, DSR, Jeddah, Saudi Arabia.</p>
    </notes>
    <notes>
      <title>Institutional Review Board Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes>
      <title>Informed Consent Statement</title>
      <p>Not applicable.</p>
    </notes>
    <notes>
      <title>Data Availability Statement</title>
      <p>The data supporting this research and that used to build the system can be acquired from the corresponding author upon request.</p>
    </notes>
    <ack>
      <title>Acknowledgments</title>
      <p>The authors extend their appreciation to the Deputyship for Research &amp; Innovation, Ministry of Education in Saudi Arabia, for funding this research work through the project number IFPRC-106-611-2020 and King Abdulaziz University, DSR, Jeddah, Saudi Arabia.</p>
    </ack>
    <notes notes-type="COI-statement">
      <title>Conflicts of Interest</title>
      <p>The authors declare no conflict of interest.</p>
    </notes>
    <ref-list>
      <title>References</title>
      <ref id="B1-mathematics-10-00683">
        <label>1.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Ullah</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
            <name>
              <surname>Habib</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Aleem</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Kundi</surname>
              <given-names>F.M.</given-names>
            </name>
            <name>
              <surname>Khattak</surname>
              <given-names>A.M.</given-names>
            </name>
          </person-group>
          <article-title>Optimizing the Efficiency of Machine Learning Techniques</article-title>
          <source>International Conference on Big Data and Security</source>
          <publisher-name>Springer</publisher-name>
          <publisher-loc>Singapore</publisher-loc>
          <month>December</month>
          <year>2020</year>
          <fpage>553</fpage>
          <lpage>567</lpage>
        </element-citation>
      </ref>
      <ref id="B2-mathematics-10-00683">
        <label>2.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Chalkidis</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Androutsopoulos</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Aletras</surname>
              <given-names>N.</given-names>
            </name>
          </person-group>
          <article-title>Neural Legal Judgment Prediction in English</article-title>
          <source>arXiv</source>
          <year>2019</year>
          <pub-id pub-id-type="arxiv">1906.02059</pub-id>
        </element-citation>
      </ref>
      <ref id="B3-mathematics-10-00683">
        <label>3.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ahmad</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.U.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Mosavi</surname>
              <given-names>A.H.</given-names>
            </name>
          </person-group>
          <article-title>A Hybrid Deep Learning Technique for Personality Trait Classification from Text</article-title>
          <source>IEEE Access</source>
          <year>2021</year>
          <volume>9</volume>
          <fpage>146214</fpage>
          <lpage>146232</lpage>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3121791</pub-id>
        </element-citation>
      </ref>
      <ref id="B4-mathematics-10-00683">
        <label>4.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Long</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Lu</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Cui</surname>
              <given-names>L.</given-names>
            </name>
          </person-group>
          <article-title>Deep learning-based feature engineering for stock price movement prediction</article-title>
          <source>Knowl. Based Syst.</source>
          <year>2019</year>
          <volume>164</volume>
          <fpage>163</fpage>
          <lpage>173</lpage>
          <pub-id pub-id-type="doi">10.1016/j.knosys.2018.10.034</pub-id>
        </element-citation>
      </ref>
      <ref id="B5-mathematics-10-00683">
        <label>5.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ali</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>El-Sappagh</surname>
              <given-names>S.</given-names>
            </name>
            <name>
              <surname>Islam</surname>
              <given-names>S.R.</given-names>
            </name>
            <name>
              <surname>Kwak</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Imran</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Kwak</surname>
              <given-names>K.-S.</given-names>
            </name>
          </person-group>
          <article-title>A smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion</article-title>
          <source>Inf. Fusion</source>
          <year>2020</year>
          <volume>63</volume>
          <fpage>208</fpage>
          <lpage>222</lpage>
          <pub-id pub-id-type="doi">10.1016/j.inffus.2020.06.008</pub-id>
        </element-citation>
      </ref>
      <ref id="B6-mathematics-10-00683">
        <label>6.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khattak</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.U.</given-names>
            </name>
            <name>
              <surname>Batool</surname>
              <given-names>U.</given-names>
            </name>
            <name>
              <surname>Ullah</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Al-Rakhami</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Gumaei</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Automatic Detection of Citrus Fruit and Leaves Diseases Using Deep Neural Network Model</article-title>
          <source>IEEE Access</source>
          <year>2021</year>
          <volume>9</volume>
          <fpage>112942</fpage>
          <lpage>112954</lpage>
          <pub-id pub-id-type="doi">10.1109/ACCESS.2021.3096895</pub-id>
        </element-citation>
      </ref>
      <ref id="B7-mathematics-10-00683">
        <label>7.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khan</surname>
              <given-names>H.M.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>F.M.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
            <name>
              <surname>Alghazzawi</surname>
              <given-names>D.M.</given-names>
            </name>
          </person-group>
          <article-title>Anomalous Behavior Detection Framework Using HTM-Based Semantic Folding Technique</article-title>
          <source>Comput. Math. Methods Med.</source>
          <year>2021</year>
          <volume>2021</volume>
          <fpage>5585238</fpage>
          <pub-id pub-id-type="doi">10.1155/2021/5585238</pub-id>
          <pub-id pub-id-type="pmid">33790986</pub-id>
        </element-citation>
      </ref>
      <ref id="B8-mathematics-10-00683">
        <label>8.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Zhu</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Hu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>Legal Judgment Prediction Based on Multiclass Information Fusion</article-title>
          <source>Complexity</source>
          <year>2020</year>
          <volume>2020</volume>
          <fpage>3089189</fpage>
          <pub-id pub-id-type="doi">10.1155/2020/3089189</pub-id>
        </element-citation>
      </ref>
      <ref id="B9-mathematics-10-00683">
        <label>9.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Shaikh</surname>
              <given-names>R.A.</given-names>
            </name>
            <name>
              <surname>Sahu</surname>
              <given-names>T.P.</given-names>
            </name>
            <name>
              <surname>Anand</surname>
              <given-names>V.</given-names>
            </name>
          </person-group>
          <article-title>Predicting Outcomes of Legal Cases based on Legal Factors using Classifiers</article-title>
          <source>Procedia Comput. Sci.</source>
          <year>2020</year>
          <volume>167</volume>
          <fpage>2393</fpage>
          <lpage>2402</lpage>
          <pub-id pub-id-type="doi">10.1016/j.procs.2020.03.292</pub-id>
        </element-citation>
      </ref>
      <ref id="B10-mathematics-10-00683">
        <label>10.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khattak</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
            <name>
              <surname>Ishaq</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Bangyal</surname>
              <given-names>W.H.</given-names>
            </name>
            <name>
              <surname>A Hameed</surname>
              <given-names>I.</given-names>
            </name>
          </person-group>
          <article-title>Enhanced concept-level sentiment analysis system with expanded ontological relations for efficient classification of user reviews</article-title>
          <source>Egypt. Inform. J.</source>
          <year>2021</year>
          <volume>22</volume>
          <fpage>455</fpage>
          <lpage>471</lpage>
          <pub-id pub-id-type="doi">10.1016/j.eij.2021.03.001</pub-id>
        </element-citation>
      </ref>
      <ref id="B11-mathematics-10-00683">
        <label>11.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Katz</surname>
              <given-names>D.M.</given-names>
            </name>
            <name>
              <surname>Bommarito</surname>
              <given-names>M.J.</given-names>
              <suffix>II</suffix>
            </name>
            <name>
              <surname>Blackman</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>A general approach for predicting the behavior of the Supreme Court of the United States</article-title>
          <source>PLoS ONE</source>
          <year>2017</year>
          <volume>12</volume>
          <elocation-id>e0174698</elocation-id>
          <pub-id pub-id-type="doi">10.1371/journal.pone.0174698</pub-id>
        </element-citation>
      </ref>
      <ref id="B12-mathematics-10-00683">
        <label>12.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Liu</surname>
              <given-names>Y.H.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>Y.L.</given-names>
            </name>
          </person-group>
          <article-title>A two-phase sentiment analysis approach for judgement prediction</article-title>
          <source>J. Inf. Sci.</source>
          <year>2018</year>
          <volume>44</volume>
          <fpage>594</fpage>
          <lpage>607</lpage>
          <pub-id pub-id-type="doi">10.1177/0165551517722741</pub-id>
        </element-citation>
      </ref>
      <ref id="B13-mathematics-10-00683">
        <label>13.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>&#x15E;ulea</surname>
              <given-names>O.-M.</given-names>
            </name>
            <name>
              <surname>Zampieri</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Vela</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>van Genabith</surname>
              <given-names>J.</given-names>
            </name>
          </person-group>
          <article-title>Predicting the law area and decisions of french supreme court cases</article-title>
          <source>arXiv</source>
          <year>2017</year>
          <pub-id pub-id-type="arxiv">1708.01681</pub-id>
        </element-citation>
      </ref>
      <ref id="B14-mathematics-10-00683">
        <label>14.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Luo</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Feng</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Xu</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Zhao</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Learning to predict charges for criminal cases with legal basis</article-title>
          <source>arXiv</source>
          <year>2017</year>
          <pub-id pub-id-type="arxiv">1707.09168</pub-id>
        </element-citation>
      </ref>
      <ref id="B15-mathematics-10-00683">
        <label>15.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ye</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Jiang</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Luo</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Chao</surname>
              <given-names>W.</given-names>
            </name>
          </person-group>
          <article-title>Interpretable charge predictions for criminal cases: Learning to generate court views from fact descriptions</article-title>
          <source>arXiv</source>
          <year>2018</year>
          <pub-id pub-id-type="arxiv">1802.08504</pub-id>
        </element-citation>
      </ref>
      <ref id="B16-mathematics-10-00683">
        <label>16.</label>
        <element-citation publication-type="confproc">
          <person-group person-group-type="author">
            <name>
              <surname>Kowsrihawat</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Vateekul</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Boonkwan</surname>
              <given-names>P.</given-names>
            </name>
          </person-group>
          <article-title>Predicting Judicial Decisions of Criminal Cases from Thai Supreme Court Using Bi-directional GRU with Attention Mechanism</article-title>
          <source>Proceedings of the 2018 5th Asian Conference on Defense Technology (ACDT)</source>
          <conf-loc>Hanoi, Vietnam</conf-loc>
          <conf-date>25&#x2013;26 October 2018</conf-date>
          <fpage>50</fpage>
          <lpage>55</lpage>
        </element-citation>
      </ref>
      <ref id="B17-mathematics-10-00683">
        <label>17.</label>
        <element-citation publication-type="confproc">
          <person-group person-group-type="author">
            <name>
              <surname>Zhong</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Guo</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Tu</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Xiao</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>Z.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Legal Judgment Prediction via Topological Learning</article-title>
          <source>Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</source>
          <conf-loc>Brussels, Belgium</conf-loc>
          <conf-date>15&#x2013;27 October 2018</conf-date>
          <fpage>3540</fpage>
          <lpage>3549</lpage>
        </element-citation>
      </ref>
      <ref id="B18-mathematics-10-00683">
        <label>18.</label>
        <element-citation publication-type="confproc">
          <person-group person-group-type="author">
            <name>
              <surname>Giri</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Porwal</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Shukla</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Chadha</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Kaushal</surname>
              <given-names>R.</given-names>
            </name>
          </person-group>
          <article-title>Approaches for information retrieval in legal documents</article-title>
          <source>Proceedings of the 2017 Tenth International Conference on Contemporary Computing (IC3)</source>
          <conf-loc>Noida, India</conf-loc>
          <conf-date>10&#x2013;12 August 2017</conf-date>
          <fpage>1</fpage>
          <lpage>6</lpage>
        </element-citation>
      </ref>
      <ref id="B19-mathematics-10-00683">
        <label>19.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Yu</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Meng</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Research and Design on Cognitive Computing Framework for Predicting Judicial Decisions</article-title>
          <source>J. Signal Process. Syst.</source>
          <year>2018</year>
          <volume>91</volume>
          <fpage>1159</fpage>
          <lpage>1167</lpage>
          <pub-id pub-id-type="doi">10.1007/s11265-018-1429-9</pub-id>
        </element-citation>
      </ref>
      <ref id="B20-mathematics-10-00683">
        <label>20.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Medvedeva</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Vols</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Wieling</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>Using machine learning to predict decisions of the European Court of Human Rights</article-title>
          <source>Artif. Intell. Law</source>
          <year>2020</year>
          <volume>28</volume>
          <fpage>237</fpage>
          <lpage>266</lpage>
          <pub-id pub-id-type="doi">10.1007/s10506-019-09255-y</pub-id>
        </element-citation>
      </ref>
      <ref id="B21-mathematics-10-00683">
        <label>21.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Hsieh</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Chen</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>T.</given-names>
            </name>
          </person-group>
          <article-title>Legal Judgment Prediction Based on Machine Learning: Predicting the Discretionary Damages of Mental Suffering in Fatal Car Accident Cases</article-title>
          <source>Appl. Sci.</source>
          <year>2021</year>
          <volume>11</volume>
          <elocation-id>10361</elocation-id>
          <pub-id pub-id-type="doi">10.3390/app112110361</pub-id>
        </element-citation>
      </ref>
      <ref id="B22-mathematics-10-00683">
        <label>22.</label>
        <element-citation publication-type="web">
          <person-group person-group-type="author">
            <name>
              <surname>Spaeth</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>The Supreme Court Database</article-title>
          <day>13</day>
          <month>September</month>
          <year>2019</year>
          <comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://scdb.wustl.edu/index.php" ext-link-type="uri">http://scdb.wustl.edu/index.php</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-11-12">(accessed on 12 November 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B23-mathematics-10-00683">
        <label>23.</label>
        <element-citation publication-type="web">
          <person-group person-group-type="author">
            <name>
              <surname>Spaeth</surname>
              <given-names>H.</given-names>
            </name>
          </person-group>
          <article-title>Online Code Book</article-title>
          <day>13</day>
          <month>September</month>
          <year>2019</year>
          <comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="http://supremecourtdatabase.org/documentation.php" ext-link-type="uri">http://supremecourtdatabase.org/documentation.php</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-10-10">(accessed on 10 October 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B24-mathematics-10-00683">
        <label>24.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Pedregosa</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Varoquaux</surname>
              <given-names>G.</given-names>
            </name>
            <name>
              <surname>Gramfort</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Michel</surname>
              <given-names>V.</given-names>
            </name>
            <name>
              <surname>Thirion</surname>
              <given-names>B.</given-names>
            </name>
            <name>
              <surname>Grisel</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Blondel</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Prettenhofer</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Weiss</surname>
              <given-names>R.</given-names>
            </name>
            <name>
              <surname>Dubourg</surname>
              <given-names>V.</given-names>
            </name>
            <etal/>
          </person-group>
          <article-title>Scikit-learn: Machine learning in Python</article-title>
          <source>J. Mach. Learn. Res.</source>
          <year>2011</year>
          <volume>12</volume>
          <fpage>2825</fpage>
          <lpage>2830</lpage>
        </element-citation>
      </ref>
      <ref id="B25-mathematics-10-00683">
        <label>25.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Alghazzawi</surname>
              <given-names>D.</given-names>
            </name>
            <name>
              <surname>Bamasag</surname>
              <given-names>O.</given-names>
            </name>
            <name>
              <surname>Ullah</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
          </person-group>
          <article-title>Efficient Detection of DDoS Attacks Using a Hybrid Deep Learning Model with Improved Feature Selection</article-title>
          <source>Appl. Sci.</source>
          <year>2021</year>
          <volume>11</volume>
          <elocation-id>11634</elocation-id>
          <pub-id pub-id-type="doi">10.3390/app112411634</pub-id>
        </element-citation>
      </ref>
      <ref id="B26-mathematics-10-00683">
        <label>26.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khan</surname>
              <given-names>A.S.</given-names>
            </name>
            <name>
              <surname>Ahmad</surname>
              <given-names>H.</given-names>
            </name>
            <name>
              <surname>Zubair</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Khan</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Arif</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Khalid</surname>
              <given-names>H.A.</given-names>
            </name>
          </person-group>
          <article-title>Personality Classification from Online Text using Machine Learning Approach</article-title>
          <source>Int. J. Adv. Comput. Sci. Appl.</source>
          <year>2020</year>
          <volume>11</volume>
          <fpage>460</fpage>
          <lpage>476</lpage>
          <pub-id pub-id-type="doi">10.14569/IJACSA.2020.0110358</pub-id>
        </element-citation>
      </ref>
      <ref id="B27-mathematics-10-00683">
        <label>27.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Li</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Yan</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <article-title>A principle component analysis-based random forest with the potential nearest neighbor method for automobile insurance fraud identification</article-title>
          <source>Appl. Soft Comput.</source>
          <year>2018</year>
          <volume>70</volume>
          <fpage>1000</fpage>
          <lpage>1009</lpage>
          <pub-id pub-id-type="doi">10.1016/j.asoc.2017.07.027</pub-id>
        </element-citation>
      </ref>
      <ref id="B28-mathematics-10-00683">
        <label>28.</label>
        <element-citation publication-type="web">
          <person-group person-group-type="author">
            <name>
              <surname>Lahoti</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>4 Ways to Implement Feature Selection in Python for Machine Learning</article-title>
          <year>2018</year>
          <comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://hub.packtpub.com/4-ways-implement-feature-selection-python-machine-learning/" ext-link-type="uri">https://hub.packtpub.com/4-ways-implement-feature-selection-python-machine-learning/</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-10-24">(accessed on 24 October 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B29-mathematics-10-00683">
        <label>29.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Yan</surname>
              <given-names>K.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>D.</given-names>
            </name>
          </person-group>
          <article-title>Feature selection and analysis on correlated gas sensor data with recursive feature elimination</article-title>
          <source>Sens. Actuators B Chem.</source>
          <year>2015</year>
          <volume>212</volume>
          <fpage>353</fpage>
          <lpage>363</lpage>
          <pub-id pub-id-type="doi">10.1016/j.snb.2015.02.025</pub-id>
        </element-citation>
      </ref>
      <ref id="B30-mathematics-10-00683">
        <label>30.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khattak</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Habib</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
            <name>
              <surname>Subhan</surname>
              <given-names>F.</given-names>
            </name>
            <name>
              <surname>Razzak</surname>
              <given-names>I.</given-names>
            </name>
            <name>
              <surname>Habib</surname>
              <given-names>A.</given-names>
            </name>
          </person-group>
          <article-title>Applying deep neural networks for user intention identification</article-title>
          <source>Soft Comput.</source>
          <year>2021</year>
          <volume>25</volume>
          <fpage>2191</fpage>
          <lpage>2220</lpage>
          <pub-id pub-id-type="doi">10.1007/s00500-020-05290-z</pub-id>
        </element-citation>
      </ref>
      <ref id="B31-mathematics-10-00683">
        <label>31.</label>
        <element-citation publication-type="book">
          <person-group person-group-type="author">
            <name>
              <surname>Grinberg</surname>
              <given-names>M.</given-names>
            </name>
          </person-group>
          <source>Flask Web Development: Developing Web Applications with Python</source>
          <publisher-name>O&#x2019;Reilly Media, Inc.</publisher-name>
          <publisher-loc>Sebastopol, CA, USA</publisher-loc>
          <year>2018</year>
          <fpage>121</fpage>
          <lpage>129</lpage>
        </element-citation>
      </ref>
      <ref id="B32-mathematics-10-00683">
        <label>32.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Ding</surname>
              <given-names>P.</given-names>
            </name>
            <name>
              <surname>Li</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Wen</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Guan</surname>
              <given-names>Y.</given-names>
            </name>
          </person-group>
          <article-title>HYBRID-CNN: An Efficient Scheme for Abnormal Flow Detection in the SDN-Based Smart Grid</article-title>
          <source>Secur. Commun. Netw.</source>
          <year>2020</year>
          <volume>2020</volume>
          <fpage>8850550</fpage>
          <pub-id pub-id-type="doi">10.1155/2020/8850550</pub-id>
        </element-citation>
      </ref>
      <ref id="B33-mathematics-10-00683">
        <label>33.</label>
        <element-citation publication-type="journal">
          <person-group person-group-type="author">
            <name>
              <surname>Khattak</surname>
              <given-names>A.</given-names>
            </name>
            <name>
              <surname>Asghar</surname>
              <given-names>M.Z.</given-names>
            </name>
            <name>
              <surname>Ali</surname>
              <given-names>M.</given-names>
            </name>
            <name>
              <surname>Batool</surname>
              <given-names>U.</given-names>
            </name>
          </person-group>
          <article-title>An efficient deep learning technique for facial emotion recognition</article-title>
          <source>Multimed. Tools Appl.</source>
          <year>2021</year>
          <volume>81</volume>
          <fpage>1649</fpage>
          <lpage>1683</lpage>
          <pub-id pub-id-type="doi">10.1007/s11042-021-11298-w</pub-id>
        </element-citation>
      </ref>
      <ref id="B34-mathematics-10-00683">
        <label>34.</label>
        <element-citation publication-type="web">
          <article-title>Three Challenges in Using Machine Learning in Industrial Applications. (n.d.). Automation.Com. Retrieved 15 February 2022</article-title>
          <comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://www.automation.com/en-us/articles/august-2020/challenges-machine-learning-industrial-application" ext-link-type="uri">https://www.automation.com/en-us/articles/august-2020/challenges-machine-learning-industrial-application</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-09-28">(accessed on 28 September 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B35-mathematics-10-00683">
        <label>35.</label>
        <element-citation publication-type="web">
          <person-group person-group-type="author">
            <name>
              <surname>Kleinberg</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Ludwig</surname>
              <given-names>J.</given-names>
            </name>
            <name>
              <surname>Mullainathan</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>A Guide to Solving Social Problems with Machine Learning. Harvard Business Review</article-title>
          <day>8</day>
          <month>December</month>
          <year>2016</year>
          <comment>Available online: <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://hbr.org/2016/12/a-guide-to-solving-social-problems-with-machine-learning" ext-link-type="uri">https://hbr.org/2016/12/a-guide-to-solving-social-problems-with-machine-learning</ext-link></comment>
          <date-in-citation content-type="access-date" iso-8601-date="2021-10-19">(accessed on 19 October 2021)</date-in-citation>
        </element-citation>
      </ref>
      <ref id="B36-mathematics-10-00683">
        <label>36.</label>
        <element-citation publication-type="confproc">
          <person-group person-group-type="author">
            <name>
              <surname>Ma</surname>
              <given-names>L.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>Y.</given-names>
            </name>
            <name>
              <surname>Wang</surname>
              <given-names>T.</given-names>
            </name>
            <name>
              <surname>Liu</surname>
              <given-names>X.</given-names>
            </name>
            <name>
              <surname>Ye</surname>
              <given-names>W.</given-names>
            </name>
            <name>
              <surname>Sun</surname>
              <given-names>C.</given-names>
            </name>
            <name>
              <surname>Zhang</surname>
              <given-names>S.</given-names>
            </name>
          </person-group>
          <article-title>Legal Judgment Prediction with Multi-Stage Case Representation Learning in the Real Court Setting</article-title>
          <source>Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval</source>
          <conf-loc>Virtual</conf-loc>
          <conf-date>11&#x2013;15 July 2021</conf-date>
          <fpage>993</fpage>
          <lpage>1002</lpage>
        </element-citation>
      </ref>
    </ref-list>
    <sec sec-type="display-objects">
      <title>Figures and Tables</title>
      <fig id="mathematics-10-00683-f001" position="float">
        <label>Figure 1</label>
        <caption>
          <p>Proposed system for predicting court judgments.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g001.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f002" position="float">
        <label>Figure 2</label>
        <caption>
          <p>Overview of the hybrid CNN+BILSTM model for court judgment system.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g002.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f003" position="float">
        <label>Figure 3</label>
        <caption>
          <p>The suggested LSTM+CNN model&#x2019;s detailed structure.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g003.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f004" position="float">
        <label>Figure 4</label>
        <caption>
          <p>Calculations of various gate configurations.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g004.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f005" position="float">
        <label>Figure 5</label>
        <caption>
          <p>Using a dropout layer.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g005.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f006" position="float">
        <label>Figure 6</label>
        <caption>
          <p>Convolution of the input and filter matrices.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g006.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f007" position="float">
        <label>Figure 7</label>
        <caption>
          <p>Applying Relu Function and addition of bias term.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g007.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f008" position="float">
        <label>Figure 8</label>
        <caption>
          <p>Applying maxpool operation.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g008.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f009" position="float">
        <label>Figure 9</label>
        <caption>
          <p>Flatten layer.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g009.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f010" position="float">
        <label>Figure 10</label>
        <caption>
          <p>Output of calculation.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g010.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f011" position="float">
        <label>Figure 11</label>
        <caption>
          <p>Classification of court judgments.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g011.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f012" position="float">
        <label>Figure 12</label>
        <caption>
          <p>Application for entering data for court judgment prediction.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g012.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f013" position="float">
        <label>Figure 13</label>
        <caption>
          <p>Create an interface that loads the training data.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g013.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f014" position="float">
        <label>Figure 14</label>
        <caption>
          <p>Interface for predicting the outcome of a court case.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g014.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f015" position="float">
        <label>Figure 15</label>
        <caption>
          <p>Study of the parameter (&#x3B1;) of training loss.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g015.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f016" position="float">
        <label>Figure 16</label>
        <caption>
          <p>Study of the parameter (&#x3B2;) of training accuracy.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g016.tif"/>
      </fig>
      <fig id="mathematics-10-00683-f017" position="float">
        <label>Figure 17</label>
        <caption>
          <p>Study of the parameter (&#x3B3;) of validation loss.</p>
        </caption>
        <graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="mathematics-10-00683-g017.tif"/>
      </fig>
      <table-wrap id="mathematics-10-00683-t001" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t001_Table 1</object-id>
        <label>Table 1</label>
        <caption>
          <p>Research objectives.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Research Objective</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Motivation</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">RO1: To forecast court case judgments using LSTM+CNN on the basis of historical judicial data.</td>
              <td align="center" valign="middle">Investigate the proposed deep neural network model (LSTM+CNN) and its application to the prediction of court case judgments using past judicial data.</td>
            </tr>
            <tr>
              <td align="center" valign="middle">RO2: To compare the efficiency of the suggested LSTM+CNN approach to that of machine learning and deep learning techniques.</td>
              <td align="center" valign="middle">Examine basic ML (k-nearest neighbours&#x2019; method (k-NN), support vector machine (SVM), random forests (RF), logistic regression (LR)) and cutting-edge DL models (CNN, LSTM, and RNN) as well as various assessment measures such as accuracy, precision, recall, and F1-score.</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">RO3: To compare the proposed technique&#x2019;s effectiveness in forecasting court case judgments from past judicial records to benchmark research.</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Compare the efficiency of the proposed DL model (LSTM+CNN) in predicting court case judgments using numerous evaluation measures such as accuracy, precision, recall, and F1-score to existing state-of-the-art baseline studies that focus on word embedding-based feature representation techniques.</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t002" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t002_Table 2</object-id>
        <label>Table 2</label>
        <caption>
          <p>A list of features without feature selection that can be used to make predictions about the judgement of a court case.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Feature ID</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Feature Name</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Description</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">1</td>
              <td align="center" valign="middle">Final decision (target variable)</td>
              <td align="center" valign="middle">How the outcome is decided (&#x201C;T1: Affirm&#x201D;, &#x201C;T2: reverse&#x201D;, &#x201C;T3: other&#x201D;)</td>
            </tr>
            <tr>
              <td align="center" valign="middle">2</td>
              <td align="center" valign="middle">Natural_Court</td>
              <td align="center" valign="middle">the epoch in which the court issued its decision</td>
            </tr>
            <tr>
              <td align="center" valign="middle">3</td>
              <td align="center" valign="middle">Petitioner</td>
              <td align="center" valign="middle">Petitioner&#x2019;s name and contact information</td>
            </tr>
            <tr>
              <td align="center" valign="middle">4</td>
              <td align="center" valign="middle">Respondent_name</td>
              <td align="center" valign="middle">Name of the respondent</td>
            </tr>
            <tr>
              <td align="center" valign="middle">5</td>
              <td align="center" valign="middle">Evidence_Type</td>
              <td align="center" valign="middle">Type of evidence</td>
            </tr>
            <tr>
              <td align="center" valign="middle">6</td>
              <td align="center" valign="middle">Origin_of_Case</td>
              <td align="center" valign="middle">The case&#x2019;s beginnings</td>
            </tr>
            <tr>
              <td align="center" valign="middle">7</td>
              <td align="center" valign="middle">no_ public_witnesses</td>
              <td align="center" valign="middle">Number of people who saw the event (public)</td>
            </tr>
            <tr>
              <td align="center" valign="middle">8</td>
              <td align="center" valign="middle">Source_of_Case</td>
              <td align="center" valign="middle">The case&#x2019;s source</td>
            </tr>
            <tr>
              <td align="center" valign="middle">9</td>
              <td align="center" valign="middle">Cert_Reason</td>
              <td align="center" valign="middle">A feature that is at the case level</td>
            </tr>
            <tr>
              <td align="center" valign="middle">10</td>
              <td align="center" valign="middle">Oigin_Court_dir</td>
              <td align="center" valign="middle">The origins of today&#x2019;s court directing round</td>
            </tr>
            <tr>
              <td align="center" valign="middle">11</td>
              <td align="center" valign="middle">Lower_Court_Decision_</td>
              <td align="center" valign="middle">Lower court&#x2019;s decision</td>
            </tr>
            <tr>
              <td align="center" valign="middle">12</td>
              <td align="center" valign="middle">__Low_Court_disag</td>
              <td align="center" valign="middle">Differences of opinion in the lower court</td>
            </tr>
            <tr>
              <td align="center" valign="middle">13</td>
              <td align="center" valign="middle">Cont_eye_witness_dis</td>
              <td align="center" valign="middle">Contradictory statements provided by eyewitnesses</td>
            </tr>
            <tr>
              <td align="center" valign="middle">14</td>
              <td align="center" valign="middle">Precedence_Alternation</td>
              <td align="center" valign="middle">Changes to the precedent note</td>
            </tr>
            <tr>
              <td align="center" valign="middle">15</td>
              <td align="center" valign="middle">no_ of_defense_witnesses</td>
              <td align="center" valign="middle">The total number of witnesses (defense)</td>
            </tr>
            <tr>
              <td align="center" valign="middle">16</td>
              <td align="center" valign="middle">Issue</td>
              <td align="center" valign="middle">A feature that is at the case level</td>
            </tr>
            <tr>
              <td align="center" valign="middle">17</td>
              <td align="center" valign="middle">Area_of_issue</td>
              <td align="center" valign="middle">A feature that is at the case level</td>
            </tr>
            <tr>
              <td align="center" valign="middle">18</td>
              <td align="center" valign="middle">Direction_of_issue</td>
              <td align="center" valign="middle">Lower court disposition instructions</td>
            </tr>
            <tr>
              <td align="center" valign="middle">19</td>
              <td align="center" valign="middle">argument_month</td>
              <td align="center" valign="middle">This keeps track of the model&#x2019;s current month</td>
            </tr>
            <tr>
              <td align="center" valign="middle">20</td>
              <td align="center" valign="middle">justice_court_difference</td>
              <td align="center" valign="middle">Z-score differences between individual justice and the entire court are recorded</td>
            </tr>
            <tr>
              <td align="center" valign="middle">21</td>
              <td align="center" valign="middle">Type_of_ Law</td>
              <td align="center" valign="middle">The type of law</td>
            </tr>
            <tr>
              <td align="center" valign="middle">22</td>
              <td align="center" valign="middle">Prosecution_ motive</td>
              <td align="center" valign="middle">The prosecution did not show that there was a reason</td>
            </tr>
            <tr>
              <td align="center" valign="middle">23</td>
              <td align="center" valign="middle">Majority_Votes</td>
              <td align="center" valign="middle">Justice agrees with the majority</td>
            </tr>
            <tr>
              <td align="center" valign="middle">24</td>
              <td align="center" valign="middle">Lower_Court_Direction_res</td>
              <td align="center" valign="middle">The lower court&#x2019;s direction to the respondent</td>
            </tr>
            <tr>
              <td align="center" valign="middle">25</td>
              <td align="center" valign="middle">Justice</td>
              <td align="center" valign="middle">A brief history of justice and the courts</td>
            </tr>
            <tr>
              <td align="center" valign="middle">26</td>
              <td align="center" valign="middle">Lower/Upper/court/difference</td>
              <td align="center" valign="middle">contradictory rulings by the lower and upper courts</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">27</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">direction_ Court</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Individual justices&#x2019; and the court&#x2019;s prior ideological behaviour</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t003" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t003_Table 3</object-id>
        <label>Table 3</label>
        <caption>
          <p>A list of optimal features for court judgments.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">S No.</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Optimal Features</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Ranking Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">1</td>
              <td align="center" valign="middle">Decision Direction</td>
              <td align="center" valign="middle">6.41</td>
            </tr>
            <tr>
              <td align="center" valign="middle">2</td>
              <td align="center" valign="middle">Opinion</td>
              <td align="center" valign="middle">6.23</td>
            </tr>
            <tr>
              <td align="center" valign="middle">3</td>
              <td align="center" valign="middle">Decision Direction Dissent</td>
              <td align="center" valign="middle">5.09</td>
            </tr>
            <tr>
              <td align="center" valign="middle">4</td>
              <td align="center" valign="middle">Respondent</td>
              <td align="center" valign="middle">4.21</td>
            </tr>
            <tr>
              <td align="center" valign="middle">5</td>
              <td align="center" valign="middle">Law Type</td>
              <td align="center" valign="middle">3.56</td>
            </tr>
            <tr>
              <td align="center" valign="middle">6</td>
              <td align="center" valign="middle">Issue</td>
              <td align="center" valign="middle">3.17</td>
            </tr>
            <tr>
              <td align="center" valign="middle">7</td>
              <td align="center" valign="middle">Lower Court Decision</td>
              <td align="center" valign="middle">3.02</td>
            </tr>
            <tr>
              <td align="center" valign="middle">8</td>
              <td align="center" valign="middle">Lower case disagreement</td>
              <td align="center" valign="middle">2.89</td>
            </tr>
            <tr>
              <td align="center" valign="middle">9</td>
              <td align="center" valign="middle">Case origin</td>
              <td align="center" valign="middle">2.42</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">10</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Petitioner</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">1.74</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t004" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t004_Table 4</object-id>
        <label>Table 4</label>
        <caption>
          <p>LSTM-CNN deep learning models&#x2019; precision.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (P1)<break/>Affirm</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (P2)<break/>Reverse</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (P3)<break/>Other</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 1</td>
              <td align="center" valign="middle">0.63</td>
              <td align="center" valign="middle">0.61</td>
              <td align="center" valign="middle">0.60</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 2</td>
              <td align="center" valign="middle">0.71</td>
              <td align="center" valign="middle">0.70</td>
              <td align="center" valign="middle">0.69</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 3</td>
              <td align="center" valign="middle">0.73</td>
              <td align="center" valign="middle">0.71</td>
              <td align="center" valign="middle">0.70</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 4</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.73</td>
              <td align="center" valign="middle">0.70</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 5</td>
              <td align="center" valign="middle">0.77</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.72</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 6</td>
              <td align="center" valign="middle">0.76</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.74</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 7</td>
              <td align="center" valign="middle">0.84</td>
              <td align="center" valign="middle">0.78</td>
              <td align="center" valign="middle">0.77</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 8</td>
              <td align="center" valign="middle">0.82</td>
              <td align="center" valign="middle">0.77</td>
              <td align="center" valign="middle">0.77</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 9</td>
              <td align="center" valign="middle">0.85</td>
              <td align="center" valign="middle">0.80</td>
              <td align="center" valign="middle">0.82</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">LSTM-CNN 10</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.92</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.91</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t005" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t005_Table 5</object-id>
        <label>Table 5</label>
        <caption>
          <p>LSTM-CNN deep learning models&#x2019; recall.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (R1)<break/>Affirm</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (R2)<break/>Reverse</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (R3)<break/>Other</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 1</td>
              <td align="center" valign="middle">0.63</td>
              <td align="center" valign="middle">0.62</td>
              <td align="center" valign="middle">0.61</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 2</td>
              <td align="center" valign="middle">0.71</td>
              <td align="center" valign="middle">0.69</td>
              <td align="center" valign="middle">0.65</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 3</td>
              <td align="center" valign="middle">0.73</td>
              <td align="center" valign="middle">0.69</td>
              <td align="center" valign="middle">0.68</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 4</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.70</td>
              <td align="center" valign="middle">0.70</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 5</td>
              <td align="center" valign="middle">0.77</td>
              <td align="center" valign="middle">0.71</td>
              <td align="center" valign="middle">0.72</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 6</td>
              <td align="center" valign="middle">0.76</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.74</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 7</td>
              <td align="center" valign="middle">0.84</td>
              <td align="center" valign="middle">0.78</td>
              <td align="center" valign="middle">0.77</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 8</td>
              <td align="center" valign="middle">0.82</td>
              <td align="center" valign="middle">0.77</td>
              <td align="center" valign="middle">0.76</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 9</td>
              <td align="center" valign="middle">0.85</td>
              <td align="center" valign="middle">0.79</td>
              <td align="center" valign="middle">0.80</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">LSTM-CNN 10</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.90</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.91</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t006" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t006_Table 6</object-id>
        <label>Table 6</label>
        <caption>
          <p>Performance measures of LSTM+CNN court case prediction models.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Macro<break/>Precision</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Micro<break/>Precision</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Macro<break/>Recall</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Micro<break/>Recall</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Macro<break/>F-Measure</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Micro<break/>F-Measure</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 1</td>
              <td align="center" valign="middle">0.77</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.80</td>
              <td align="center" valign="middle">0.74</td>
              <td align="center" valign="middle">0.79</td>
              <td align="center" valign="middle">0.74</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 2</td>
              <td align="center" valign="middle">0.80</td>
              <td align="center" valign="middle">0.79</td>
              <td align="center" valign="middle">0.82</td>
              <td align="center" valign="middle">0.79</td>
              <td align="center" valign="middle">0.81</td>
              <td align="center" valign="middle">0.79</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 3</td>
              <td align="center" valign="middle">0.81</td>
              <td align="center" valign="middle">0.80</td>
              <td align="center" valign="middle">0.85</td>
              <td align="center" valign="middle">0.80</td>
              <td align="center" valign="middle">0.83</td>
              <td align="center" valign="middle">0.80</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 4</td>
              <td align="center" valign="middle">0.83</td>
              <td align="center" valign="middle">0.83</td>
              <td align="center" valign="middle">0.89</td>
              <td align="center" valign="middle">0.83</td>
              <td align="center" valign="middle">0.86</td>
              <td align="center" valign="middle">0.83</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 5</td>
              <td align="center" valign="middle">0.85</td>
              <td align="center" valign="middle">0.84</td>
              <td align="center" valign="middle">0.88</td>
              <td align="center" valign="middle">0.84</td>
              <td align="center" valign="middle">0.86</td>
              <td align="center" valign="middle">0.84</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 6</td>
              <td align="center" valign="middle">0.86</td>
              <td align="center" valign="middle">0.87</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.87</td>
              <td align="center" valign="middle">0.89</td>
              <td align="center" valign="middle">0.87</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 7</td>
              <td align="center" valign="middle">0.89</td>
              <td align="center" valign="middle">0.88</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.88</td>
              <td align="center" valign="middle">0.90</td>
              <td align="center" valign="middle">0.88</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 8</td>
              <td align="center" valign="middle">0.90</td>
              <td align="center" valign="middle">0.89</td>
              <td align="center" valign="middle">0.90</td>
              <td align="center" valign="middle">0.90</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.90</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 9</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.90</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.91</td>
              <td align="center" valign="middle">0.92</td>
              <td align="center" valign="middle">0.91</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">LSTM-CNN 10</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.92</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.94</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.92</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.93</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t007" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t007_Table 7</object-id>
        <label>Table 7</label>
        <caption>
          <p>Evaluation of the LSTM+CNN model&#x2019;s performance with and without feature selection with feature selection.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Performance Measure</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Without Feature Selection</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">With Feature Selection</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">Accuracy (%)</td>
              <td align="center" valign="middle">88</td>
              <td align="center" valign="middle">92.05</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Precision (%)</td>
              <td align="center" valign="middle">88</td>
              <td align="center" valign="middle">93</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Recall (%)</td>
              <td align="center" valign="middle">87</td>
              <td align="center" valign="middle">94</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">F1-score</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">87</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">93</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t008" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t008_Table 8</object-id>
        <label>Table 8</label>
        <caption>
          <p>The LSTM+CNN models&#x2019; test accuracy, test loss, and training time.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Test Accuracy</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Test Loss</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Train Time (Seconds)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 1</td>
              <td align="center" valign="middle">83.13%</td>
              <td align="center" valign="middle">0.82</td>
              <td align="center" valign="middle">15 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 2</td>
              <td align="center" valign="middle">84.11%</td>
              <td align="center" valign="middle">0.87</td>
              <td align="center" valign="middle">2 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 3</td>
              <td align="center" valign="middle">84.61%</td>
              <td align="center" valign="middle">1.08</td>
              <td align="center" valign="middle">14 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 4</td>
              <td align="center" valign="middle">85.57%</td>
              <td align="center" valign="middle">1.17</td>
              <td align="center" valign="middle">12 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 5</td>
              <td align="center" valign="middle">85.88%</td>
              <td align="center" valign="middle">0.97</td>
              <td align="center" valign="middle">3 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 6</td>
              <td align="center" valign="middle">89.37%</td>
              <td align="center" valign="middle">0.95</td>
              <td align="center" valign="middle">10 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 7</td>
              <td align="center" valign="middle">90.11%</td>
              <td align="center" valign="middle">1.15</td>
              <td align="center" valign="middle">8 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 8</td>
              <td align="center" valign="middle">90.16%</td>
              <td align="center" valign="middle">0.85</td>
              <td align="center" valign="middle">19 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM-CNN 9</td>
              <td align="center" valign="middle">91.13%</td>
              <td align="center" valign="middle">0.95</td>
              <td align="center" valign="middle">6 s</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">LSTM-CNN 10</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">92.05%</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.86</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">7 s</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t009" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t009_Table 9</object-id>
        <label>Table 9</label>
        <caption>
          <p>Comparison performance with feature selection and without feature selection (training vs. testing times).</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin"> </th>
              <th rowspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy</th>
              <th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Time in Seconds</th>
            </tr>
            <tr>
              <th align="center" valign="middle" style="border-bottom:solid thin">Train Time</th>
              <th align="center" valign="middle" style="border-bottom:solid thin">Test Time</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">Without Feature Selection</td>
              <td align="center" valign="middle">88 (%)</td>
              <td align="center" valign="middle">125.4</td>
              <td align="center" valign="middle">2.7</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">With Feature Selection</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">92.05 (%)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">77.4</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">1.0</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t010" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t010_Table 10</object-id>
        <label>Table 10</label>
        <caption>
          <p>Performance of LSTM+CNN (proposed) and classical SVM.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy (Avg. Percent)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Computing Overhead (in min)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">Classical SVM</td>
              <td align="center" valign="middle">89</td>
              <td align="center" valign="middle">8.51</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">LSTM+CNN (proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">92.05%</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">6.08</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t011" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t011_Table 11</object-id>
        <label>Table 11</label>
        <caption>
          <p>Performance comparison of the suggested model (LSTM+CNN) versus machine learning models.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Methods/Classifier</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Recall (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">f-Score (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">KNN</td>
              <td align="center" valign="middle">74</td>
              <td align="center" valign="middle">75</td>
              <td align="center" valign="middle">75</td>
              <td align="center" valign="middle">75</td>
            </tr>
            <tr>
              <td align="center" valign="middle">SVM</td>
              <td align="center" valign="middle">78</td>
              <td align="center" valign="middle">79</td>
              <td align="center" valign="middle">78</td>
              <td align="center" valign="middle">79</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LR</td>
              <td align="center" valign="middle">80</td>
              <td align="center" valign="middle">79</td>
              <td align="center" valign="middle">79</td>
              <td align="center" valign="middle">79</td>
            </tr>
            <tr>
              <td align="center" valign="middle">RF</td>
              <td align="center" valign="middle">69</td>
              <td align="center" valign="middle">68</td>
              <td align="center" valign="middle">68</td>
              <td align="center" valign="middle">68</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Proposed (LSTM+CNN)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">92.05</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">94</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">93</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t012" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t012_Table 12</object-id>
        <label>Table 12</label>
        <caption>
          <p>The proposed model (LSTM+CNN) versus various DL models.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">DL Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Recall (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">f-Score (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">CNN</td>
              <td align="center" valign="middle">83.36</td>
              <td align="center" valign="middle">83</td>
              <td align="center" valign="middle">84</td>
              <td align="center" valign="middle">83</td>
            </tr>
            <tr>
              <td align="center" valign="middle">RNN</td>
              <td align="center" valign="middle">81.42</td>
              <td align="center" valign="middle">81</td>
              <td align="center" valign="middle">82</td>
              <td align="center" valign="middle">81</td>
            </tr>
            <tr>
              <td align="center" valign="middle">LSTM</td>
              <td align="center" valign="middle">80.11</td>
              <td align="center" valign="middle">80</td>
              <td align="center" valign="middle">81</td>
              <td align="center" valign="middle">80</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Proposed (LSTM-CNN)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">92.05</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">93</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">94</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">93</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t013" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t013_Table 13</object-id>
        <label>Table 13</label>
        <caption>
          <p>Performance evaluation of LSTM+CNN model in ablation Study.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Model</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Precision (%)</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Recall (%)</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM+CNN with FS</td>
              <td align="center" valign="middle">92.05</td>
              <td align="center" valign="middle">93</td>
              <td align="center" valign="middle">94</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Model 1 (without FS)</td>
              <td align="center" valign="middle">87</td>
              <td align="center" valign="middle">85</td>
              <td align="center" valign="middle">84</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Model 2 (without balancing)</td>
              <td align="center" valign="middle">84</td>
              <td align="center" valign="middle">85</td>
              <td align="center" valign="middle">81</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Model 3 (without LSTM)</td>
              <td align="center" valign="middle">80</td>
              <td align="center" valign="middle">82</td>
              <td align="center" valign="middle">83</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Model 4 (without CNN)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">79</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">82</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">80</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t014" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t014_Table 14</object-id>
        <label>Table 14</label>
        <caption>
          <p>Comparison of the LSTM+CNN model to comparable studies.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Research</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Approach</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Results That Have Been Recorded on the Dataset</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Results Based on a Dataset</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">Ullah et al. [<xref ref-type="bibr" rid="B1-mathematics-10-00683">1</xref>]</td>
              <td align="center" valign="middle">Predicting court rulings with the use of machine learning.</td>
              <td align="center" valign="middle">Acc: 64%</td>
              <td align="center" valign="middle">Acc: 61%</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Zhu et al. [<xref ref-type="bibr" rid="B8-mathematics-10-00683">8</xref>]</td>
              <td align="center" valign="middle">Forecasting judicial rulings using machine learning.</td>
              <td align="center" valign="middle">Acc. 88%</td>
              <td align="center" valign="middle">Acc. 78%</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Medvedeva et al. [<xref ref-type="bibr" rid="B20-mathematics-10-00683">20</xref>]</td>
              <td align="center" valign="middle">Predicts violations of nine articles of the European Convention on Human Rights</td>
              <td align="center" valign="middle">Acc. 89%</td>
              <td align="center" valign="middle">Acc. 79.3%</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Hsieh et al. [<xref ref-type="bibr" rid="B21-mathematics-10-00683">21</xref>]</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Machine Learning for Predicting Legal Decisions in the Courtroom</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Acc. 90.2%</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Acc. 78.5%</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t015" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t015_Table 15</object-id>
        <label>Table 15</label>
        <caption>
          <p>Differences in the efficiency of LR(ML) and LSTM-CNN(DL) via significant testing.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin"> </th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">True Classification with the LR</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Misclassification of the LR</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Total</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td align="center" valign="middle">LSTM-CNN classification that is correct</td>
              <td align="center" valign="middle">71</td>
              <td align="center" valign="middle">10</td>
              <td align="center" valign="middle">81</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Misclassification of the LSTM-CNN</td>
              <td align="center" valign="middle">12</td>
              <td align="center" valign="middle">20</td>
              <td align="center" valign="middle">32</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Total</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">83</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">30</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">113</td>
            </tr>
          </tbody>
        </table>
        <table-wrap-foot>
          <fn>
            <p>McNemar&#x2019;s chi-square values are 1.5 when the degree of freedom is one. In this case, McNemar&#x2019;s chi-square values are 1.5, and the degree of freedom is 1. The p-value is 0.200 with two tails, and the McNemar&#x2019;s chi-square values are 1.5 with a degree of freedom of one. As indicated by the value of p (p 0.5), the null hypothesis is rejected, and the alternative hypothesis is accepted. (In other words, the suggested vs. baseline models are statistically significant.).</p>
          </fn>
        </table-wrap-foot>
      </table-wrap>
      <table-wrap id="mathematics-10-00683-t016" position="float">
        <object-id pub-id-type="pii">mathematics-10-00683-t016_Table 16</object-id>
        <label>Table 16</label>
        <caption>
          <p>The external evaluation of the proposed method.</p>
        </caption>
        <table>
          <thead>
            <tr>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Dataset</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">The Volume of Data in the Dataset</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Feature Selection</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Balanced Dataset</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Sensitivity</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Specificity</th>
              <th align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin">Accuracy</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">SC (US) 2014</td>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">8735</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.142</td>
              <td align="center" valign="middle">0.921</td>
              <td align="center" valign="middle">0.896</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.186</td>
              <td align="center" valign="middle">0.942</td>
              <td align="center" valign="middle">0.910</td>
            </tr>
            <tr>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">0.735</td>
              <td align="center" valign="middle">0.776</td>
              <td align="center" valign="middle">0.790</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.808</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.807</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.805</td>
            </tr>
            <tr>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">SC (US) (2013)</td>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">9032</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.139</td>
              <td align="center" valign="middle">0.931</td>
              <td align="center" valign="middle">0.883</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.153</td>
              <td align="center" valign="middle">0.937</td>
              <td align="center" valign="middle">0.852</td>
            </tr>
            <tr>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">0.745</td>
              <td align="center" valign="middle">0.761</td>
              <td align="center" valign="middle">0.761</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.806</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.804</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.796</td>
            </tr>
            <tr>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">SC (US) (2012)</td>
              <td rowspan="4" align="center" valign="middle" style="border-bottom:solid thin">5961</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.146</td>
              <td align="center" valign="middle">0.948</td>
              <td align="center" valign="middle">0.881</td>
            </tr>
            <tr>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">0.166</td>
              <td align="center" valign="middle">0.947</td>
              <td align="center" valign="middle">0.922</td>
            </tr>
            <tr>
              <td align="center" valign="middle">No</td>
              <td align="center" valign="middle">Yes</td>
              <td align="center" valign="middle">0.744</td>
              <td align="center" valign="middle">0.772</td>
              <td align="center" valign="middle">0.796</td>
            </tr>
            <tr>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">Yes(proposed)</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.817</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.814</td>
              <td align="center" valign="middle" style="border-bottom:solid thin">0.824</td>
            </tr>
          </tbody>
        </table>
      </table-wrap>
    </sec>
    <fn-group>
      <fn>
        <p><bold>Publisher&#x2019;s Note:</bold> MDPI stays neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p>
      </fn>
    </fn-group>
  </back>
</article>
